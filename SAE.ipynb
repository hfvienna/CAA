{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/root/CAA', '/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages', '/root/CAA/venv/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMER FIX\n",
    "import sys\n",
    "sys.path.append('/root/CAA/venv/lib/python3.10/site-packages')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from behaviors import ALL_BEHAVIORS, BASE_DIR, COORDINATE, get_vector_path\n",
    "from gemma_2_wrapper import Gemma2Wrapper\n",
    "from generate_vectors import generate_save_vectors_for_behavior\n",
    "import gemma_vector_analysis\n",
    "from huggingface_hub import hf_hub_download\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from behaviors import ALL_BEHAVIORS, BASE_DIR, COORDINATE, get_vector_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3169687dccc14af09a1588359ed8f94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params.npz:   0%|          | 0.00/19.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "#Load SAE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 12\n",
    "\n",
    "# Load the SAE model\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_1m/average_l0_207/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"Success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE model width: Encoder width = 1048576, Decoder width = 1048576\n"
     ]
    }
   ],
   "source": [
    "print(f\"SAE model width: Encoder width = {sae.W_enc.shape[1]}, Decoder width = {sae.W_dec.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing vector for behavior: sycophancy\n",
      "Vector shape: torch.Size([2304])\n",
      "Using device: cuda\n",
      "Norm of the original vector: 42.7291\n",
      "First 20 entries of the vector:\n",
      "tensor([ 0.1404, -0.4736, -0.0243,  1.1708,  0.8371, -0.7364,  1.7948,  0.8291,\n",
      "         1.6945,  0.3871,  0.4149, -0.8828,  1.4796, -0.9835,  0.2753,  0.6525,\n",
      "        -0.8137,  1.2188, -0.5540, -0.0628], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Load CAA Vector\n",
    "behavior = \"sycophancy\"\n",
    "model_name_path = 'gemma-2-2b'\n",
    "vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "\n",
    "# Load the existing normalized vector\n",
    "original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "caa_vector = torch.load(original_path)\n",
    "\n",
    "print(f\"Analyzing vector for behavior: {behavior}\")\n",
    "print(f\"Vector shape: {caa_vector.shape}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move caa_vector to device\n",
    "caa_vector = caa_vector.to(device)\n",
    "\n",
    "print(f\"Norm of the original vector: {caa_vector.norm().item():.4f}\")\n",
    "print(\"First 20 entries of the vector:\")\n",
    "print(caa_vector[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector shape: torch.Size([2304])\n",
      "Norm of the forwarded vector: 111.7115\n",
      "First 20 entries of the vector:\n",
      "tensor([-0.6929,  0.8543,  0.2417,  0.2384,  2.3269,  2.0966,  1.3398, -1.1441,\n",
      "        -0.3486,  1.4361,  0.6083,  2.3244,  3.4588, -2.4025,  0.8034, -2.9251,\n",
      "         0.1457, -2.1802, -6.9103,  0.4804], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Forward CAA vector in SAE\n",
    "forwarded_caa_vector = sae.forward(caa_vector)\n",
    "print(f\"Vector shape: {forwarded_caa_vector.shape}\")\n",
    "print(f\"Norm of the forwarded vector: {forwarded_caa_vector.norm().item():.4f}\")\n",
    "print(\"First 20 entries of the vector:\")\n",
    "print(forwarded_caa_vector[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between original and forwarded vector: 0.2163\n"
     ]
    }
   ],
   "source": [
    "#Cosine similarity after forward\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ensure both vectors are on the same device and have the same shape\n",
    "caa_vector = caa_vector.to(device)\n",
    "forwarded_caa_vector = forwarded_caa_vector.to(device)\n",
    "\n",
    "# Reshape vectors to 2D if they're not already (cosine_similarity expects 2D tensors)\n",
    "caa_vector = caa_vector.view(1, -1)\n",
    "forwarded_caa_vector = forwarded_caa_vector.view(1, -1)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = F.cosine_similarity(caa_vector, forwarded_caa_vector, dim=1)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Cosine similarity between original and forwarded vector: {cosine_sim.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the downloaded file after use\n",
    "if os.path.exists(path_to_params):\n",
    "    #os.remove(path_to_params)\n",
    "    #print(f\"Deleted the downloaded file: {path_to_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
