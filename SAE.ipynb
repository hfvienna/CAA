{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis file is intended to identify the optimal method for reconstructing a CAA vector using an SAE model.\\n\\nIt is research code, the exploration code been generated by Claude 3.5 and was not proof-read.\\n\\n1. Should the code not run, try upgrading transformers in your env:\\npip install --upgrade transformers\\n\\n2. The next cell is a system path fix. It may or may not be necessary to run in your environment.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This file is intended to identify the optimal method for reconstructing a CAA vector using an SAE model.\n",
    "\n",
    "It is research code, the exploration code been generated by Claude 3.5 and was not proof-read.\n",
    "\n",
    "1. Should the code not run, try upgrading transformers in your env:\n",
    "pip install --upgrade transformers\n",
    "\n",
    "2. The next cell is a system path fix. It may or may not be necessary to run in your environment.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages', '/root/CAA/venv/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMER / ENVIRONMENT FIX\n",
    "import sys\n",
    "sys.path.append('/root/CAA/venv/lib/python3.10/site-packages')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from behaviors import ALL_BEHAVIORS, BASE_DIR, COORDINATE, get_vector_path\n",
    "from gemma_2_wrapper import Gemma2Wrapper\n",
    "from generate_vectors import generate_save_vectors_for_behavior\n",
    "import gemma_vector_analysis\n",
    "from huggingface_hub import hf_hub_download\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT 1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=15, use_leaky_relu=True, negative_slope=0.01):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        caa_vector_scaled = caa_vector * scale_factor\n",
    "        adjusted_vector = caa_vector_scaled + self.b_dec\n",
    "        pre_acts = adjusted_vector @ self.W_enc + self.b_enc\n",
    "        \n",
    "        if use_leaky_relu:\n",
    "            encoded = F.leaky_relu(pre_acts, negative_slope=negative_slope)\n",
    "        else:\n",
    "            encoded = F.relu(pre_acts)\n",
    "        \n",
    "        decoded = encoded @ self.W_dec + self.b_dec\n",
    "        decoded_adjusted = decoded - self.b_dec\n",
    "        decoded_normalized = F.normalize(decoded_adjusted, dim=-1)\n",
    "        return decoded_normalized\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.logspace(0, 2, 20)\n",
    "    use_leaky_relu_options = [True, False]\n",
    "    negative_slopes = [0.01, 0.1, 0.2]\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        for use_leaky_relu in use_leaky_relu_options:\n",
    "            for negative_slope in negative_slopes:\n",
    "                similarities = []\n",
    "                \n",
    "                for behavior, caa_vector in caa_vectors.items():\n",
    "                    caa_vector = caa_vector.to(device)\n",
    "                    forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor, use_leaky_relu, negative_slope)\n",
    "                    \n",
    "                    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "                    similarities.append(cosine_sim.item())\n",
    "                \n",
    "                avg_similarity = np.mean(similarities)\n",
    "                \n",
    "                if avg_similarity > best_avg_similarity:\n",
    "                    best_avg_similarity = avg_similarity\n",
    "                    best_params = {\n",
    "                        'scale_factor': scale_factor,\n",
    "                        'use_leaky_relu': use_leaky_relu,\n",
    "                        'negative_slope': negative_slope\n",
    "                    }\n",
    "                \n",
    "                print(f\"Scale: {scale_factor:.2f}, Leaky ReLU: {use_leaky_relu}, Slope: {negative_slope:.2f}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"Success\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    behavior = behavior\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Analyzing vector for behavior: {behavior}\")\n",
    "    \n",
    "    caa_vector = caa_vector.to(device)\n",
    "    \n",
    "    forwarded_caa_vector = sae.process_caa_vector(caa_vector)\n",
    "    print(f\"Norm of the forwarded vector: {forwarded_caa_vector.norm().item():.4f}\")\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved forwarded vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "    \n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = forwarded_caa_vector.to(device)\n",
    "    \n",
    "    caa_vector = caa_vector.view(1, -1)\n",
    "    forwarded_caa_vector = forwarded_caa_vector.view(1, -1)\n",
    "    \n",
    "    cosine_sim = F.cosine_similarity(caa_vector, forwarded_caa_vector, dim=1)\n",
    "    \n",
    "    print(f\"Cosine similarity between original and forwarded vector: {cosine_sim.item():.4f}\")\n",
    "\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "print(f\"\\nBest parameters found:\")\n",
    "print(f\"Scale factor: {best_params['scale_factor']:.2f}\")\n",
    "print(f\"Use Leaky ReLU: {best_params['use_leaky_relu']}\")\n",
    "print(f\"Negative slope: {best_params['negative_slope']:.2f}\")\n",
    "print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(\n",
    "        caa_vector, \n",
    "        best_params['scale_factor'], \n",
    "        best_params['use_leaky_relu'], \n",
    "        best_params['negative_slope']\n",
    "    )\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved optimized forwarded vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Optimized cosine similarity for {behavior}: {cosine_sim.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPERIMENT 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=15, activation='leaky_relu', activation_param=0.01):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        caa_vector_scaled = caa_vector * scale_factor\n",
    "        adjusted_vector = caa_vector_scaled + self.b_dec\n",
    "        pre_acts = adjusted_vector @ self.W_enc + self.b_enc\n",
    "        \n",
    "        if activation == 'leaky_relu':\n",
    "            encoded = F.leaky_relu(pre_acts, negative_slope=activation_param)\n",
    "        elif activation == 'elu':\n",
    "            encoded = F.elu(pre_acts, alpha=activation_param)\n",
    "        elif activation == 'selu':\n",
    "            encoded = F.selu(pre_acts)\n",
    "        else:\n",
    "            encoded = F.relu(pre_acts)\n",
    "        \n",
    "        decoded = encoded @ self.W_dec + self.b_dec\n",
    "        decoded_adjusted = decoded - self.b_dec\n",
    "        decoded_normalized = F.normalize(decoded_adjusted, dim=-1)\n",
    "        return decoded_normalized\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.logspace(0, 3, 30)  # Expanded range and more granular\n",
    "    activations = ['leaky_relu', 'elu', 'selu', 'relu']\n",
    "    activation_params = np.logspace(-3, 0, 10)  # For leaky_relu and elu\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        for activation in activations:\n",
    "            if activation in ['leaky_relu', 'elu']:\n",
    "                params_to_test = activation_params\n",
    "            else:\n",
    "                params_to_test = [0]  # Dummy value for selu and relu\n",
    "            \n",
    "            for activation_param in params_to_test:\n",
    "                similarities = []\n",
    "                \n",
    "                for behavior, caa_vector in caa_vectors.items():\n",
    "                    caa_vector = caa_vector.to(device)\n",
    "                    forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor, activation, activation_param)\n",
    "                    \n",
    "                    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "                    similarities.append(cosine_sim.item())\n",
    "                \n",
    "                avg_similarity = np.mean(similarities)\n",
    "                \n",
    "                if avg_similarity > best_avg_similarity:\n",
    "                    best_avg_similarity = avg_similarity\n",
    "                    best_params = {\n",
    "                        'scale_factor': scale_factor,\n",
    "                        'activation': activation,\n",
    "                        'activation_param': activation_param\n",
    "                    }\n",
    "                \n",
    "                print(f\"Scale: {scale_factor:.2f}, Activation: {activation}, Param: {activation_param:.4f}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"Success\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    behavior = behavior\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Analyzing vector for behavior: {behavior}\")\n",
    "    \n",
    "    caa_vector = caa_vector.to(device)\n",
    "    \n",
    "    forwarded_caa_vector = sae.process_caa_vector(caa_vector)\n",
    "    print(f\"Norm of the forwarded vector: {forwarded_caa_vector.norm().item():.4f}\")\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved forwarded vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "    \n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = forwarded_caa_vector.to(device)\n",
    "    \n",
    "    caa_vector = caa_vector.view(1, -1)\n",
    "    forwarded_caa_vector = forwarded_caa_vector.view(1, -1)\n",
    "    \n",
    "    cosine_sim = F.cosine_similarity(caa_vector, forwarded_caa_vector, dim=1)\n",
    "    \n",
    "    print(f\"Cosine similarity between original and forwarded vector: {cosine_sim.item():.4f}\")\n",
    "\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "print(f\"\\nBest parameters found:\")\n",
    "print(f\"Scale factor: {best_params['scale_factor']:.2f}\")\n",
    "print(f\"Activation: {best_params['activation']}\")\n",
    "print(f\"Activation parameter: {best_params['activation_param']:.4f}\")\n",
    "print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(\n",
    "        caa_vector, \n",
    "        best_params['scale_factor'], \n",
    "        best_params['activation'], \n",
    "        best_params['activation_param']\n",
    "    )\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved optimized forwarded vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Optimized cosine similarity for {behavior}: {cosine_sim.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPERIMENT 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=1.0):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        caa_vector_scaled = caa_vector * scale_factor\n",
    "        adjusted_vector = caa_vector_scaled + self.b_dec\n",
    "        encoded = self.encode(adjusted_vector)\n",
    "        decoded = self.decode(encoded)\n",
    "        decoded_adjusted = decoded - self.b_dec\n",
    "        return decoded_adjusted\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.linspace(0.1, 10, 100)  # More reasonable range\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        similarities = []\n",
    "        \n",
    "        for behavior, caa_vector in caa_vectors.items():\n",
    "            caa_vector = caa_vector.to(device)\n",
    "            forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor)\n",
    "            \n",
    "            cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "            similarities.append(cosine_sim.item())\n",
    "        \n",
    "        avg_similarity = np.mean(similarities)\n",
    "        \n",
    "        if avg_similarity > best_avg_similarity:\n",
    "            best_avg_similarity = avg_similarity\n",
    "            best_params = {'scale_factor': scale_factor}\n",
    "        \n",
    "        print(f\"Scale: {scale_factor:.2f}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "print(\"Optimizing parameters...\")\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "print(f\"\\nBest parameters found:\")\n",
    "print(f\"Scale factor: {best_params['scale_factor']:.4f}\")\n",
    "print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "print(\"\\nProcessing CAA vectors with optimized parameters:\")\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(caa_vector, best_params['scale_factor'])\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Cosine similarity for {behavior}: {cosine_sim.item():.4f}\")\n",
    "\n",
    "    # Calculate and print L2 norm of the original and processed vectors\n",
    "    original_norm = torch.norm(caa_vector).item()\n",
    "    processed_norm = torch.norm(forwarded_caa_vector).item()\n",
    "    print(f\"L2 norm - Original: {original_norm:.4f}, Processed: {processed_norm:.4f}\")\n",
    "\n",
    "    # Calculate and print mean and standard deviation of the original and processed vectors\n",
    "    original_mean = torch.mean(caa_vector).item()\n",
    "    original_std = torch.std(caa_vector).item()\n",
    "    processed_mean = torch.mean(forwarded_caa_vector).item()\n",
    "    processed_std = torch.std(forwarded_caa_vector).item()\n",
    "    print(f\"Mean - Original: {original_mean:.4f}, Processed: {processed_mean:.4f}\")\n",
    "    print(f\"Std Dev - Original: {original_std:.4f}, Processed: {processed_std:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPERIMENT 4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=1.0, target_norm=None):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        \n",
    "        # Add back the \"canceled out\" information\n",
    "        adjusted_vector = caa_vector + self.b_dec\n",
    "        \n",
    "        # Scale to match typical residual activation magnitude\n",
    "        if target_norm is not None:\n",
    "            current_norm = torch.norm(adjusted_vector)\n",
    "            adjusted_vector = adjusted_vector * (target_norm / current_norm)\n",
    "        else:\n",
    "            adjusted_vector = adjusted_vector * scale_factor\n",
    "        \n",
    "        # Process through SAE\n",
    "        encoded = self.encode(adjusted_vector)\n",
    "        decoded = self.decode(encoded)\n",
    "        \n",
    "        # Normalize the output\n",
    "        decoded_normalized = F.normalize(decoded, dim=-1)\n",
    "        \n",
    "        return decoded_normalized\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.linspace(0.1, 10, 100)\n",
    "    target_norms = np.linspace(10, 1000, 100)\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        for target_norm in target_norms:\n",
    "            similarities = []\n",
    "            \n",
    "            for behavior, caa_vector in caa_vectors.items():\n",
    "                caa_vector = caa_vector.to(device)\n",
    "                forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor, target_norm)\n",
    "                \n",
    "                cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "                similarities.append(cosine_sim.item())\n",
    "            \n",
    "            avg_similarity = np.mean(similarities)\n",
    "            \n",
    "            if avg_similarity > best_avg_similarity:\n",
    "                best_avg_similarity = avg_similarity\n",
    "                best_params = {'scale_factor': scale_factor, 'target_norm': target_norm}\n",
    "            \n",
    "            print(f\"Scale: {scale_factor:.2f}, Target Norm: {target_norm:.2f}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "print(\"Optimizing parameters...\")\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "#print(f\"\\nBest parameters found:\")\n",
    "#print(f\"Scale factor: {best_params['scale_factor']:.4f}\")\n",
    "#print(f\"Target norm: {best_params['target_norm']:.4f}\")\n",
    "#print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "print(\"\\nProcessing CAA vectors with optimized parameters:\")\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(caa_vector, best_params['scale_factor'], best_params['target_norm'])\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Cosine similarity for {behavior}: {cosine_sim.item():.4f}\")\n",
    "\n",
    "    # Calculate and print L2 norm of the original and processed vectors\n",
    "    original_norm = torch.norm(caa_vector).item()\n",
    "    processed_norm = torch.norm(forwarded_caa_vector).item()\n",
    "    print(f\"L2 norm - Original: {original_norm:.4f}, Processed: {processed_norm:.4f}\")\n",
    "\n",
    "    # Calculate and print mean and standard deviation of the original and processed vectors\n",
    "    original_mean = torch.mean(caa_vector).item()\n",
    "    original_std = torch.std(caa_vector).item()\n",
    "    processed_mean = torch.mean(forwarded_caa_vector).item()\n",
    "    processed_std = torch.std(forwarded_caa_vector).item()\n",
    "    print(f\"Mean - Original: {original_mean:.4f}, Processed: {processed_mean:.4f}\")\n",
    "    print(f\"Std Dev - Original: {original_std:.4f}, Processed: {processed_std:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPERIMENT 5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=1.0, add_bias=False, normalize_input=False):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        \n",
    "        if add_bias:\n",
    "            adjusted_vector = caa_vector + self.b_dec\n",
    "        else:\n",
    "            adjusted_vector = caa_vector\n",
    "\n",
    "        adjusted_vector = adjusted_vector * scale_factor\n",
    "        \n",
    "        if normalize_input:\n",
    "            adjusted_vector = F.normalize(adjusted_vector, dim=-1)\n",
    "        \n",
    "        encoded = self.encode(adjusted_vector)\n",
    "        decoded = self.decode(encoded)\n",
    "        \n",
    "        return decoded\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.logspace(0, 3, 20)\n",
    "    add_bias_options = [True, False]\n",
    "    normalize_input_options = [True, False]\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        for add_bias in add_bias_options:\n",
    "            for normalize_input in normalize_input_options:\n",
    "                similarities = []\n",
    "                \n",
    "                for behavior, caa_vector in caa_vectors.items():\n",
    "                    caa_vector = caa_vector.to(device)\n",
    "                    forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor, add_bias, normalize_input)\n",
    "                    \n",
    "                    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "                    similarities.append(cosine_sim.item())\n",
    "                \n",
    "                avg_similarity = np.mean(similarities)\n",
    "                \n",
    "                if avg_similarity > best_avg_similarity:\n",
    "                    best_avg_similarity = avg_similarity\n",
    "                    best_params = {\n",
    "                        'scale_factor': scale_factor,\n",
    "                        'add_bias': add_bias,\n",
    "                        'normalize_input': normalize_input\n",
    "                    }\n",
    "                \n",
    "                print(f\"Scale: {scale_factor:.2f}, Add Bias: {add_bias}, Normalize Input: {normalize_input}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "print(f\"SAE model width: Encoder width = {sae.W_enc.shape[1]}, Decoder width = {sae.W_dec.shape[0]}\")\n",
    "print(\"Decoder bias (b_dec) statistics:\")\n",
    "print(f\"Shape: {sae.b_dec.shape}\")\n",
    "print(f\"Mean: {sae.b_dec.mean().item():.4f}\")\n",
    "print(f\"Std Dev: {sae.b_dec.std().item():.4f}\")\n",
    "print(f\"Min: {sae.b_dec.min().item():.4f}\")\n",
    "print(f\"Max: {sae.b_dec.max().item():.4f}\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "print(\"Optimizing parameters...\")\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "print(f\"\\nBest parameters found:\")\n",
    "print(f\"Scale factor: {best_params['scale_factor']:.4f}\")\n",
    "print(f\"Add bias: {best_params['add_bias']}\")\n",
    "print(f\"Normalize input: {best_params['normalize_input']}\")\n",
    "print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "print(\"\\nProcessing CAA vectors with optimized parameters:\")\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(\n",
    "        caa_vector,\n",
    "        best_params['scale_factor'],\n",
    "        best_params['add_bias'],\n",
    "        best_params['normalize_input']\n",
    "    )\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Cosine similarity for {behavior}: {cosine_sim.item():.4f}\")\n",
    "\n",
    "    original_norm = torch.norm(caa_vector).item()\n",
    "    processed_norm = torch.norm(forwarded_caa_vector).item()\n",
    "    print(f\"L2 norm - Original: {original_norm:.4f}, Processed: {processed_norm:.4f}\")\n",
    "\n",
    "    original_mean = torch.mean(caa_vector).item()\n",
    "    original_std = torch.std(caa_vector).item()\n",
    "    processed_mean = torch.mean(forwarded_caa_vector).item()\n",
    "    processed_std = torch.std(forwarded_caa_vector).item()\n",
    "    print(f\"Mean - Original: {original_mean:.4f}, Processed: {processed_mean:.4f}\")\n",
    "    print(f\"Std Dev - Original: {original_std:.4f}, Processed: {processed_std:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPERIMENT 6 (simple model only using scale)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=4.2813):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        adjusted_vector = caa_vector * scale_factor\n",
    "        encoded = self.encode(adjusted_vector)\n",
    "        decoded = self.decode(encoded)\n",
    "        return decoded\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors, scale_factor):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        processed_vector = sae.process_caa_vector(caa_vector, scale_factor)\n",
    "        \n",
    "        cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), processed_vector.view(1, -1), dim=1)\n",
    "        similarities.append(cosine_sim.item())\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim.item():.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors\n",
    "scale_factor = 4.2813  # This value was found to work well in previous experiments\n",
    "processed_vectors = process_caa_vectors(sae, caa_vectors, scale_factor)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        decoder_bias = self.b_dec\n",
    "        \n",
    "        # Compute SAE(caa_vector + decoder_bias) and SAE(-caa_vector + decoder_bias)\n",
    "        positive_encoded = self.encode(caa_vector + decoder_bias)\n",
    "        negative_encoded = self.encode(-caa_vector + decoder_bias)\n",
    "        \n",
    "        positive_decoded = self.decode(positive_encoded)\n",
    "        negative_decoded = self.decode(negative_encoded)\n",
    "        \n",
    "        # Calculate (positive - negative) / 2\n",
    "        result_vector = (positive_decoded - negative_decoded) / 2\n",
    "        \n",
    "        # Calculate cosine similarity between result_vector and caa_vector\n",
    "        cosine_sim = F.cosine_similarity(result_vector.view(1, -1), caa_vector.view(1, -1), dim=1).item()\n",
    "        \n",
    "        return result_vector, cosine_sim\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        \n",
    "        # Unpack the tuple returned by sae.process_caa_vector\n",
    "        processed_vector, cosine_sim = sae.process_caa_vector(caa_vector)\n",
    "        \n",
    "        similarities.append(cosine_sim)\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors\n",
    "processed_vectors = process_caa_vectors(sae, caa_vectors)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE loaded successfully\n",
      "Loaded CAA vector for behavior: coordinate-other-ais\n",
      "Loaded CAA vector for behavior: corrigible-neutral-HHH\n",
      "Loaded CAA vector for behavior: hallucination\n",
      "Loaded CAA vector for behavior: myopic-reward\n",
      "Loaded CAA vector for behavior: survival-instinct\n",
      "Loaded CAA vector for behavior: sycophancy\n",
      "Loaded CAA vector for behavior: refusal\n",
      "Processed vector for behavior: coordinate-other-ais\n",
      "Cosine similarity: 0.7200\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 21.7290\n",
      "Original mean: 0.0521\n",
      "Processed mean: 0.0035\n",
      "Original std dev: 0.9230\n",
      "Processed std dev: 0.4528\n",
      "\n",
      "Processed vector for behavior: corrigible-neutral-HHH\n",
      "Cosine similarity: 0.7304\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 24.5254\n",
      "Original mean: 0.0128\n",
      "Processed mean: 0.0032\n",
      "Original std dev: 0.9243\n",
      "Processed std dev: 0.5110\n",
      "\n",
      "Processed vector for behavior: hallucination\n",
      "Cosine similarity: 0.5983\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 15.9928\n",
      "Original mean: 0.0288\n",
      "Processed mean: -0.0008\n",
      "Original std dev: 0.9240\n",
      "Processed std dev: 0.3333\n",
      "\n",
      "Processed vector for behavior: myopic-reward\n",
      "Cosine similarity: 0.7342\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 28.2953\n",
      "Original mean: 0.0039\n",
      "Processed mean: -0.0022\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 0.5896\n",
      "\n",
      "Processed vector for behavior: survival-instinct\n",
      "Cosine similarity: 0.5632\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 16.8127\n",
      "Original mean: -0.0186\n",
      "Processed mean: -0.0020\n",
      "Original std dev: 0.9242\n",
      "Processed std dev: 0.3503\n",
      "\n",
      "Processed vector for behavior: sycophancy\n",
      "Cosine similarity: 0.4835\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 15.7873\n",
      "Original mean: 0.0089\n",
      "Processed mean: -0.0059\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 0.3289\n",
      "\n",
      "Processed vector for behavior: refusal\n",
      "Cosine similarity: 0.5036\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 12.4166\n",
      "Original mean: -0.0370\n",
      "Processed mean: -0.0069\n",
      "Original std dev: 0.9237\n",
      "Processed std dev: 0.2586\n",
      "\n",
      "Average cosine similarity: 0.6190\n",
      "Saved processed vector for behavior coordinate-other-ais at /root/CAA/sae_vector/processed_coordinate-other-ais.pt\n",
      "Saved processed vector for behavior corrigible-neutral-HHH at /root/CAA/sae_vector/processed_corrigible-neutral-HHH.pt\n",
      "Saved processed vector for behavior hallucination at /root/CAA/sae_vector/processed_hallucination.pt\n",
      "Saved processed vector for behavior myopic-reward at /root/CAA/sae_vector/processed_myopic-reward.pt\n",
      "Saved processed vector for behavior survival-instinct at /root/CAA/sae_vector/processed_survival-instinct.pt\n",
      "Saved processed vector for behavior sycophancy at /root/CAA/sae_vector/processed_sycophancy.pt\n",
      "Saved processed vector for behavior refusal at /root/CAA/sae_vector/processed_refusal.pt\n",
      "CAA vector processing complete.\n"
     ]
    }
   ],
   "source": [
    "#Experiment 8, Nina suggestion incl. neg. CAA vector, no scaling\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        decoder_bias = self.b_dec\n",
    "        \n",
    "        # Compute SAE(caa_vector + decoder_bias) and SAE(-caa_vector + decoder_bias)\n",
    "        positive_encoded = self.encode(caa_vector + decoder_bias)\n",
    "        negative_encoded = self.encode(-caa_vector + decoder_bias)\n",
    "        \n",
    "        positive_decoded = self.decode(positive_encoded)\n",
    "        negative_decoded = self.decode(negative_encoded)\n",
    "        \n",
    "        # Calculate (positive - negative) / 2\n",
    "        result_vector = (positive_decoded - negative_decoded) / 2\n",
    "        \n",
    "        # Calculate cosine similarity between result_vector and caa_vector\n",
    "        cosine_sim = F.cosine_similarity(result_vector.view(1, -1), caa_vector.view(1, -1), dim=1).item()\n",
    "        \n",
    "        return result_vector, cosine_sim\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        \n",
    "        # Unpack the tuple returned by sae.process_caa_vector\n",
    "        processed_vector, cosine_sim = sae.process_caa_vector(caa_vector)\n",
    "        \n",
    "        similarities.append(cosine_sim)\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors\n",
    "processed_vectors = process_caa_vectors(sae, caa_vectors)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE loaded successfully\n",
      "Loaded CAA vector for behavior: coordinate-other-ais\n",
      "Loaded CAA vector for behavior: corrigible-neutral-HHH\n",
      "Loaded CAA vector for behavior: hallucination\n",
      "Loaded CAA vector for behavior: myopic-reward\n",
      "Loaded CAA vector for behavior: survival-instinct\n",
      "Loaded CAA vector for behavior: sycophancy\n",
      "Loaded CAA vector for behavior: refusal\n",
      "Processing with scaling:\n",
      "Processed vector for behavior: coordinate-other-ais\n",
      "Cosine similarity: 0.8658\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 255.2028\n",
      "Original mean: 0.0521\n",
      "Processed mean: 0.1877\n",
      "Original std dev: 0.9230\n",
      "Processed std dev: 5.3146\n",
      "\n",
      "Processed vector for behavior: corrigible-neutral-HHH\n",
      "Cosine similarity: 0.8685\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 268.3082\n",
      "Original mean: 0.0128\n",
      "Processed mean: 0.0354\n",
      "Original std dev: 0.9243\n",
      "Processed std dev: 5.5909\n",
      "\n",
      "Processed vector for behavior: hallucination\n",
      "Cosine similarity: 0.8456\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 241.0766\n",
      "Original mean: 0.0288\n",
      "Processed mean: 0.1753\n",
      "Original std dev: 0.9240\n",
      "Processed std dev: 5.0205\n",
      "\n",
      "Processed vector for behavior: myopic-reward\n",
      "Cosine similarity: 0.8897\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 193.2522\n",
      "Original mean: 0.0039\n",
      "Processed mean: -0.0211\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 4.0269\n",
      "\n",
      "Processed vector for behavior: survival-instinct\n",
      "Cosine similarity: 0.8538\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 212.8642\n",
      "Original mean: -0.0186\n",
      "Processed mean: -0.0488\n",
      "Original std dev: 0.9242\n",
      "Processed std dev: 4.4354\n",
      "\n",
      "Processed vector for behavior: sycophancy\n",
      "Cosine similarity: 0.8502\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 207.0221\n",
      "Original mean: 0.0089\n",
      "Processed mean: 0.0609\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 4.3135\n",
      "\n",
      "Processed vector for behavior: refusal\n",
      "Cosine similarity: 0.8543\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 232.5123\n",
      "Original mean: -0.0370\n",
      "Processed mean: -0.2305\n",
      "Original std dev: 0.9237\n",
      "Processed std dev: 4.8396\n",
      "\n",
      "Average cosine similarity: 0.8611\n",
      "\n",
      "Processing without scaling:\n",
      "Processed vector for behavior: coordinate-other-ais\n",
      "Cosine similarity: 0.7200\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 21.7290\n",
      "Original mean: 0.0521\n",
      "Processed mean: 0.0035\n",
      "Original std dev: 0.9230\n",
      "Processed std dev: 0.4528\n",
      "\n",
      "Processed vector for behavior: corrigible-neutral-HHH\n",
      "Cosine similarity: 0.7304\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 24.5254\n",
      "Original mean: 0.0128\n",
      "Processed mean: 0.0032\n",
      "Original std dev: 0.9243\n",
      "Processed std dev: 0.5110\n",
      "\n",
      "Processed vector for behavior: hallucination\n",
      "Cosine similarity: 0.5983\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 15.9928\n",
      "Original mean: 0.0288\n",
      "Processed mean: -0.0008\n",
      "Original std dev: 0.9240\n",
      "Processed std dev: 0.3333\n",
      "\n",
      "Processed vector for behavior: myopic-reward\n",
      "Cosine similarity: 0.7342\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 28.2953\n",
      "Original mean: 0.0039\n",
      "Processed mean: -0.0022\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 0.5896\n",
      "\n",
      "Processed vector for behavior: survival-instinct\n",
      "Cosine similarity: 0.5632\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 16.8127\n",
      "Original mean: -0.0186\n",
      "Processed mean: -0.0020\n",
      "Original std dev: 0.9242\n",
      "Processed std dev: 0.3503\n",
      "\n",
      "Processed vector for behavior: sycophancy\n",
      "Cosine similarity: 0.4835\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 15.7873\n",
      "Original mean: 0.0089\n",
      "Processed mean: -0.0059\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 0.3289\n",
      "\n",
      "Processed vector for behavior: refusal\n",
      "Cosine similarity: 0.5036\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 12.4166\n",
      "Original mean: -0.0370\n",
      "Processed mean: -0.0069\n",
      "Original std dev: 0.9237\n",
      "Processed std dev: 0.2586\n",
      "\n",
      "Average cosine similarity: 0.6190\n",
      "Saved processed scaled vector for behavior coordinate-other-ais at /root/CAA/sae_vector/processed_scaled_coordinate-other-ais.pt\n",
      "Saved processed scaled vector for behavior corrigible-neutral-HHH at /root/CAA/sae_vector/processed_scaled_corrigible-neutral-HHH.pt\n",
      "Saved processed scaled vector for behavior hallucination at /root/CAA/sae_vector/processed_scaled_hallucination.pt\n",
      "Saved processed scaled vector for behavior myopic-reward at /root/CAA/sae_vector/processed_scaled_myopic-reward.pt\n",
      "Saved processed scaled vector for behavior survival-instinct at /root/CAA/sae_vector/processed_scaled_survival-instinct.pt\n",
      "Saved processed scaled vector for behavior sycophancy at /root/CAA/sae_vector/processed_scaled_sycophancy.pt\n",
      "Saved processed scaled vector for behavior refusal at /root/CAA/sae_vector/processed_scaled_refusal.pt\n",
      "Saved processed non-scaled vector for behavior coordinate-other-ais at /root/CAA/sae_vector/processed_no_scale_coordinate-other-ais.pt\n",
      "Saved processed non-scaled vector for behavior corrigible-neutral-HHH at /root/CAA/sae_vector/processed_no_scale_corrigible-neutral-HHH.pt\n",
      "Saved processed non-scaled vector for behavior hallucination at /root/CAA/sae_vector/processed_no_scale_hallucination.pt\n",
      "Saved processed non-scaled vector for behavior myopic-reward at /root/CAA/sae_vector/processed_no_scale_myopic-reward.pt\n",
      "Saved processed non-scaled vector for behavior survival-instinct at /root/CAA/sae_vector/processed_no_scale_survival-instinct.pt\n",
      "Saved processed non-scaled vector for behavior sycophancy at /root/CAA/sae_vector/processed_no_scale_sycophancy.pt\n",
      "Saved processed non-scaled vector for behavior refusal at /root/CAA/sae_vector/processed_no_scale_refusal.pt\n",
      "CAA vector processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Experiment 9, Nina suggestion plus scaling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=None):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        decoder_bias = self.b_dec\n",
    "\n",
    "        if scale_factor is not None:\n",
    "            caa_vector = caa_vector * scale_factor\n",
    "\n",
    "        # Compute SAE(caa_vector + decoder_bias) and SAE(-caa_vector + decoder_bias)\n",
    "        positive_encoded = self.encode(caa_vector + decoder_bias)\n",
    "        negative_encoded = self.encode(-caa_vector + decoder_bias)\n",
    "        \n",
    "        positive_decoded = self.decode(positive_encoded)\n",
    "        negative_decoded = self.decode(negative_encoded)\n",
    "        \n",
    "        # Calculate (positive - negative) / 2\n",
    "        result_vector = (positive_decoded - negative_decoded) / 2\n",
    "        \n",
    "        # Calculate cosine similarity between result_vector and caa_vector\n",
    "        cosine_sim = F.cosine_similarity(result_vector.view(1, -1), caa_vector.view(1, -1), dim=1).item()\n",
    "        \n",
    "        return result_vector, cosine_sim\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors, scale_factor=None):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        \n",
    "        # Process the CAA vector with or without scaling\n",
    "        processed_vector, cosine_sim = sae.process_caa_vector(caa_vector, scale_factor=scale_factor)\n",
    "        \n",
    "        similarities.append(cosine_sim)\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors with and without scaling\n",
    "scale_factor = 4.2813  # Define your scale factor here\n",
    "print(\"Processing with scaling:\")\n",
    "processed_vectors_scaled = process_caa_vectors(sae, caa_vectors, scale_factor=scale_factor)\n",
    "\n",
    "print(\"\\nProcessing without scaling:\")\n",
    "processed_vectors_no_scale = process_caa_vectors(sae, caa_vectors, scale_factor=None)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "# Save scaled vectors\n",
    "for behavior, processed_vector in processed_vectors_scaled.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_scaled_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed scaled vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "# Save non-scaled vectors\n",
    "for behavior, processed_vector in processed_vectors_no_scale.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_no_scale_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed non-scaled vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#VERIFY SAE SELECTED\n",
    "print(f\"SAE model width: Encoder width = {sae.W_enc.shape[1]}, Decoder width = {sae.W_dec.shape[0]}\")\n",
    "print(sae.b_dec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
