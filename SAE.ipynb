{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis file is intended to identify the optimal method for reconstructing a CAA vector using an SAE model.\\n\\nIt is research code, the exploration code been generated by Claude 3.5 and was not proof-read.\\n\\n1. Should the code not run, try upgrading transformers in your env:\\npip install --upgrade transformers\\n\\n2. The next cell is a system path fix. It may or may not be necessary to run in your environment.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This file is intended to identify the optimal method for reconstructing a CAA vector using an SAE model.\n",
    "\n",
    "It is research code, the exploration code been generated by Claude 3.5 and was not proof-read.\n",
    "\n",
    "1. Should the code not run, try upgrading transformers in your env:\n",
    "pip install --upgrade transformers\n",
    "\n",
    "2. The next cell is a system path fix. It may or may not be necessary to run in your environment.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages', '/root/CAA/venv/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMER / ENVIRONMENT FIX\n",
    "import sys\n",
    "sys.path.append('/root/CAA/venv/lib/python3.10/site-packages')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from behaviors import ALL_BEHAVIORS, BASE_DIR, COORDINATE, get_vector_path\n",
    "from gemma_2_wrapper import Gemma2Wrapper\n",
    "from generate_vectors import generate_save_vectors_for_behavior\n",
    "import gemma_vector_analysis\n",
    "from huggingface_hub import hf_hub_download\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT 1 (EACH EXPERIMENT CAN BE RUN INDEPENDENTLY, YOU CAN JUMP TO EXP 9\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=15, use_leaky_relu=True, negative_slope=0.01):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        caa_vector_scaled = caa_vector * scale_factor\n",
    "        adjusted_vector = caa_vector_scaled + self.b_dec\n",
    "        pre_acts = adjusted_vector @ self.W_enc + self.b_enc\n",
    "        \n",
    "        if use_leaky_relu:\n",
    "            encoded = F.leaky_relu(pre_acts, negative_slope=negative_slope)\n",
    "        else:\n",
    "            encoded = F.relu(pre_acts)\n",
    "        \n",
    "        decoded = encoded @ self.W_dec + self.b_dec\n",
    "        decoded_adjusted = decoded - self.b_dec\n",
    "        decoded_normalized = F.normalize(decoded_adjusted, dim=-1)\n",
    "        return decoded_normalized\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.logspace(0, 2, 20)\n",
    "    use_leaky_relu_options = [True, False]\n",
    "    negative_slopes = [0.01, 0.1, 0.2]\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        for use_leaky_relu in use_leaky_relu_options:\n",
    "            for negative_slope in negative_slopes:\n",
    "                similarities = []\n",
    "                \n",
    "                for behavior, caa_vector in caa_vectors.items():\n",
    "                    caa_vector = caa_vector.to(device)\n",
    "                    forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor, use_leaky_relu, negative_slope)\n",
    "                    \n",
    "                    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "                    similarities.append(cosine_sim.item())\n",
    "                \n",
    "                avg_similarity = np.mean(similarities)\n",
    "                \n",
    "                if avg_similarity > best_avg_similarity:\n",
    "                    best_avg_similarity = avg_similarity\n",
    "                    best_params = {\n",
    "                        'scale_factor': scale_factor,\n",
    "                        'use_leaky_relu': use_leaky_relu,\n",
    "                        'negative_slope': negative_slope\n",
    "                    }\n",
    "                \n",
    "                print(f\"Scale: {scale_factor:.2f}, Leaky ReLU: {use_leaky_relu}, Slope: {negative_slope:.2f}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"Success\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    behavior = behavior\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Analyzing vector for behavior: {behavior}\")\n",
    "    \n",
    "    caa_vector = caa_vector.to(device)\n",
    "    \n",
    "    forwarded_caa_vector = sae.process_caa_vector(caa_vector)\n",
    "    print(f\"Norm of the forwarded vector: {forwarded_caa_vector.norm().item():.4f}\")\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved forwarded vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "    \n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = forwarded_caa_vector.to(device)\n",
    "    \n",
    "    caa_vector = caa_vector.view(1, -1)\n",
    "    forwarded_caa_vector = forwarded_caa_vector.view(1, -1)\n",
    "    \n",
    "    cosine_sim = F.cosine_similarity(caa_vector, forwarded_caa_vector, dim=1)\n",
    "    \n",
    "    print(f\"Cosine similarity between original and forwarded vector: {cosine_sim.item():.4f}\")\n",
    "\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "print(f\"\\nBest parameters found:\")\n",
    "print(f\"Scale factor: {best_params['scale_factor']:.2f}\")\n",
    "print(f\"Use Leaky ReLU: {best_params['use_leaky_relu']}\")\n",
    "print(f\"Negative slope: {best_params['negative_slope']:.2f}\")\n",
    "print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(\n",
    "        caa_vector, \n",
    "        best_params['scale_factor'], \n",
    "        best_params['use_leaky_relu'], \n",
    "        best_params['negative_slope']\n",
    "    )\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved optimized forwarded vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Optimized cosine similarity for {behavior}: {cosine_sim.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#EXPERIMENT 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=15, activation='leaky_relu', activation_param=0.01):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        caa_vector_scaled = caa_vector * scale_factor\n",
    "        adjusted_vector = caa_vector_scaled + self.b_dec\n",
    "        pre_acts = adjusted_vector @ self.W_enc + self.b_enc\n",
    "        \n",
    "        if activation == 'leaky_relu':\n",
    "            encoded = F.leaky_relu(pre_acts, negative_slope=activation_param)\n",
    "        elif activation == 'elu':\n",
    "            encoded = F.elu(pre_acts, alpha=activation_param)\n",
    "        elif activation == 'selu':\n",
    "            encoded = F.selu(pre_acts)\n",
    "        else:\n",
    "            encoded = F.relu(pre_acts)\n",
    "        \n",
    "        decoded = encoded @ self.W_dec + self.b_dec\n",
    "        decoded_adjusted = decoded - self.b_dec\n",
    "        decoded_normalized = F.normalize(decoded_adjusted, dim=-1)\n",
    "        return decoded_normalized\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.logspace(0, 3, 30)  # Expanded range and more granular\n",
    "    activations = ['leaky_relu', 'elu', 'selu', 'relu']\n",
    "    activation_params = np.logspace(-3, 0, 10)  # For leaky_relu and elu\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        for activation in activations:\n",
    "            if activation in ['leaky_relu', 'elu']:\n",
    "                params_to_test = activation_params\n",
    "            else:\n",
    "                params_to_test = [0]  # Dummy value for selu and relu\n",
    "            \n",
    "            for activation_param in params_to_test:\n",
    "                similarities = []\n",
    "                \n",
    "                for behavior, caa_vector in caa_vectors.items():\n",
    "                    caa_vector = caa_vector.to(device)\n",
    "                    forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor, activation, activation_param)\n",
    "                    \n",
    "                    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "                    similarities.append(cosine_sim.item())\n",
    "                \n",
    "                avg_similarity = np.mean(similarities)\n",
    "                \n",
    "                if avg_similarity > best_avg_similarity:\n",
    "                    best_avg_similarity = avg_similarity\n",
    "                    best_params = {\n",
    "                        'scale_factor': scale_factor,\n",
    "                        'activation': activation,\n",
    "                        'activation_param': activation_param\n",
    "                    }\n",
    "                \n",
    "                print(f\"Scale: {scale_factor:.2f}, Activation: {activation}, Param: {activation_param:.4f}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"Success\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    behavior = behavior\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Analyzing vector for behavior: {behavior}\")\n",
    "    \n",
    "    caa_vector = caa_vector.to(device)\n",
    "    \n",
    "    forwarded_caa_vector = sae.process_caa_vector(caa_vector)\n",
    "    print(f\"Norm of the forwarded vector: {forwarded_caa_vector.norm().item():.4f}\")\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved forwarded vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "    \n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = forwarded_caa_vector.to(device)\n",
    "    \n",
    "    caa_vector = caa_vector.view(1, -1)\n",
    "    forwarded_caa_vector = forwarded_caa_vector.view(1, -1)\n",
    "    \n",
    "    cosine_sim = F.cosine_similarity(caa_vector, forwarded_caa_vector, dim=1)\n",
    "    \n",
    "    print(f\"Cosine similarity between original and forwarded vector: {cosine_sim.item():.4f}\")\n",
    "\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "print(f\"\\nBest parameters found:\")\n",
    "print(f\"Scale factor: {best_params['scale_factor']:.2f}\")\n",
    "print(f\"Activation: {best_params['activation']}\")\n",
    "print(f\"Activation parameter: {best_params['activation_param']:.4f}\")\n",
    "print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(\n",
    "        caa_vector, \n",
    "        best_params['scale_factor'], \n",
    "        best_params['activation'], \n",
    "        best_params['activation_param']\n",
    "    )\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved optimized forwarded vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Optimized cosine similarity for {behavior}: {cosine_sim.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#EXPERIMENT 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=1.0):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        caa_vector_scaled = caa_vector * scale_factor\n",
    "        adjusted_vector = caa_vector_scaled + self.b_dec\n",
    "        encoded = self.encode(adjusted_vector)\n",
    "        decoded = self.decode(encoded)\n",
    "        decoded_adjusted = decoded - self.b_dec\n",
    "        return decoded_adjusted\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.linspace(0.1, 10, 100)  # More reasonable range\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        similarities = []\n",
    "        \n",
    "        for behavior, caa_vector in caa_vectors.items():\n",
    "            caa_vector = caa_vector.to(device)\n",
    "            forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor)\n",
    "            \n",
    "            cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "            similarities.append(cosine_sim.item())\n",
    "        \n",
    "        avg_similarity = np.mean(similarities)\n",
    "        \n",
    "        if avg_similarity > best_avg_similarity:\n",
    "            best_avg_similarity = avg_similarity\n",
    "            best_params = {'scale_factor': scale_factor}\n",
    "        \n",
    "        print(f\"Scale: {scale_factor:.2f}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "print(\"Optimizing parameters...\")\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "print(f\"\\nBest parameters found:\")\n",
    "print(f\"Scale factor: {best_params['scale_factor']:.4f}\")\n",
    "print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "print(\"\\nProcessing CAA vectors with optimized parameters:\")\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(caa_vector, best_params['scale_factor'])\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Cosine similarity for {behavior}: {cosine_sim.item():.4f}\")\n",
    "\n",
    "    # Calculate and print L2 norm of the original and processed vectors\n",
    "    original_norm = torch.norm(caa_vector).item()\n",
    "    processed_norm = torch.norm(forwarded_caa_vector).item()\n",
    "    print(f\"L2 norm - Original: {original_norm:.4f}, Processed: {processed_norm:.4f}\")\n",
    "\n",
    "    # Calculate and print mean and standard deviation of the original and processed vectors\n",
    "    original_mean = torch.mean(caa_vector).item()\n",
    "    original_std = torch.std(caa_vector).item()\n",
    "    processed_mean = torch.mean(forwarded_caa_vector).item()\n",
    "    processed_std = torch.std(forwarded_caa_vector).item()\n",
    "    print(f\"Mean - Original: {original_mean:.4f}, Processed: {processed_mean:.4f}\")\n",
    "    print(f\"Std Dev - Original: {original_std:.4f}, Processed: {processed_std:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#EXPERIMENT 4\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=1.0, target_norm=None):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        \n",
    "        # Add back the \"canceled out\" information\n",
    "        adjusted_vector = caa_vector + self.b_dec\n",
    "        \n",
    "        # Scale to match typical residual activation magnitude\n",
    "        if target_norm is not None:\n",
    "            current_norm = torch.norm(adjusted_vector)\n",
    "            adjusted_vector = adjusted_vector * (target_norm / current_norm)\n",
    "        else:\n",
    "            adjusted_vector = adjusted_vector * scale_factor\n",
    "        \n",
    "        # Process through SAE\n",
    "        encoded = self.encode(adjusted_vector)\n",
    "        decoded = self.decode(encoded)\n",
    "        \n",
    "        # Normalize the output\n",
    "        decoded_normalized = F.normalize(decoded, dim=-1)\n",
    "        \n",
    "        return decoded_normalized\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.linspace(0.1, 10, 100)\n",
    "    target_norms = np.linspace(10, 1000, 100)\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        for target_norm in target_norms:\n",
    "            similarities = []\n",
    "            \n",
    "            for behavior, caa_vector in caa_vectors.items():\n",
    "                caa_vector = caa_vector.to(device)\n",
    "                forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor, target_norm)\n",
    "                \n",
    "                cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "                similarities.append(cosine_sim.item())\n",
    "            \n",
    "            avg_similarity = np.mean(similarities)\n",
    "            \n",
    "            if avg_similarity > best_avg_similarity:\n",
    "                best_avg_similarity = avg_similarity\n",
    "                best_params = {'scale_factor': scale_factor, 'target_norm': target_norm}\n",
    "            \n",
    "            print(f\"Scale: {scale_factor:.2f}, Target Norm: {target_norm:.2f}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "print(\"Optimizing parameters...\")\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "#print(f\"\\nBest parameters found:\")\n",
    "#print(f\"Scale factor: {best_params['scale_factor']:.4f}\")\n",
    "#print(f\"Target norm: {best_params['target_norm']:.4f}\")\n",
    "#print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "print(\"\\nProcessing CAA vectors with optimized parameters:\")\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(caa_vector, best_params['scale_factor'], best_params['target_norm'])\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Cosine similarity for {behavior}: {cosine_sim.item():.4f}\")\n",
    "\n",
    "    # Calculate and print L2 norm of the original and processed vectors\n",
    "    original_norm = torch.norm(caa_vector).item()\n",
    "    processed_norm = torch.norm(forwarded_caa_vector).item()\n",
    "    print(f\"L2 norm - Original: {original_norm:.4f}, Processed: {processed_norm:.4f}\")\n",
    "\n",
    "    # Calculate and print mean and standard deviation of the original and processed vectors\n",
    "    original_mean = torch.mean(caa_vector).item()\n",
    "    original_std = torch.std(caa_vector).item()\n",
    "    processed_mean = torch.mean(forwarded_caa_vector).item()\n",
    "    processed_std = torch.std(forwarded_caa_vector).item()\n",
    "    print(f\"Mean - Original: {original_mean:.4f}, Processed: {processed_mean:.4f}\")\n",
    "    print(f\"Std Dev - Original: {original_std:.4f}, Processed: {processed_std:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#EXPERIMENT 5\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=1.0, add_bias=False, normalize_input=False):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        \n",
    "        if add_bias:\n",
    "            adjusted_vector = caa_vector + self.b_dec\n",
    "        else:\n",
    "            adjusted_vector = caa_vector\n",
    "\n",
    "        adjusted_vector = adjusted_vector * scale_factor\n",
    "        \n",
    "        if normalize_input:\n",
    "            adjusted_vector = F.normalize(adjusted_vector, dim=-1)\n",
    "        \n",
    "        encoded = self.encode(adjusted_vector)\n",
    "        decoded = self.decode(encoded)\n",
    "        \n",
    "        return decoded\n",
    "\n",
    "def optimize_parameters(sae, caa_vectors, device):\n",
    "    best_avg_similarity = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    scale_factors = np.logspace(0, 3, 20)\n",
    "    add_bias_options = [True, False]\n",
    "    normalize_input_options = [True, False]\n",
    "    \n",
    "    for scale_factor in scale_factors:\n",
    "        for add_bias in add_bias_options:\n",
    "            for normalize_input in normalize_input_options:\n",
    "                similarities = []\n",
    "                \n",
    "                for behavior, caa_vector in caa_vectors.items():\n",
    "                    caa_vector = caa_vector.to(device)\n",
    "                    forwarded_caa_vector = sae.process_caa_vector(caa_vector, scale_factor, add_bias, normalize_input)\n",
    "                    \n",
    "                    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "                    similarities.append(cosine_sim.item())\n",
    "                \n",
    "                avg_similarity = np.mean(similarities)\n",
    "                \n",
    "                if avg_similarity > best_avg_similarity:\n",
    "                    best_avg_similarity = avg_similarity\n",
    "                    best_params = {\n",
    "                        'scale_factor': scale_factor,\n",
    "                        'add_bias': add_bias,\n",
    "                        'normalize_input': normalize_input\n",
    "                    }\n",
    "                \n",
    "                print(f\"Scale: {scale_factor:.2f}, Add Bias: {add_bias}, Normalize Input: {normalize_input}, Avg Similarity: {avg_similarity:.4f}\")\n",
    "\n",
    "    return best_params, best_avg_similarity\n",
    "\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "print(f\"SAE model width: Encoder width = {sae.W_enc.shape[1]}, Decoder width = {sae.W_dec.shape[0]}\")\n",
    "print(\"Decoder bias (b_dec) statistics:\")\n",
    "print(f\"Shape: {sae.b_dec.shape}\")\n",
    "print(f\"Mean: {sae.b_dec.mean().item():.4f}\")\n",
    "print(f\"Std Dev: {sae.b_dec.std().item():.4f}\")\n",
    "print(f\"Min: {sae.b_dec.min().item():.4f}\")\n",
    "print(f\"Max: {sae.b_dec.max().item():.4f}\")\n",
    "\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "print(\"Optimizing parameters...\")\n",
    "best_params, best_avg_similarity = optimize_parameters(sae, caa_vectors, device)\n",
    "\n",
    "print(f\"\\nBest parameters found:\")\n",
    "print(f\"Scale factor: {best_params['scale_factor']:.4f}\")\n",
    "print(f\"Add bias: {best_params['add_bias']}\")\n",
    "print(f\"Normalize input: {best_params['normalize_input']}\")\n",
    "print(f\"Best average cosine similarity: {best_avg_similarity:.4f}\")\n",
    "\n",
    "print(\"\\nProcessing CAA vectors with optimized parameters:\")\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    forwarded_caa_vector = sae.process_caa_vector(\n",
    "        caa_vector,\n",
    "        best_params['scale_factor'],\n",
    "        best_params['add_bias'],\n",
    "        best_params['normalize_input']\n",
    "    )\n",
    "    \n",
    "    sae_vector_dir = '/root/CAA/sae_vector'\n",
    "    if not os.path.exists(sae_vector_dir):\n",
    "        os.makedirs(sae_vector_dir)\n",
    "    \n",
    "    forwarded_vector_path = os.path.join(sae_vector_dir, f\"forwarded_{behavior}.pt\")\n",
    "    torch.save(forwarded_caa_vector.cpu(), forwarded_vector_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {forwarded_vector_path}\")\n",
    "\n",
    "    cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), forwarded_caa_vector.view(1, -1), dim=1)\n",
    "    print(f\"Cosine similarity for {behavior}: {cosine_sim.item():.4f}\")\n",
    "\n",
    "    original_norm = torch.norm(caa_vector).item()\n",
    "    processed_norm = torch.norm(forwarded_caa_vector).item()\n",
    "    print(f\"L2 norm - Original: {original_norm:.4f}, Processed: {processed_norm:.4f}\")\n",
    "\n",
    "    original_mean = torch.mean(caa_vector).item()\n",
    "    original_std = torch.std(caa_vector).item()\n",
    "    processed_mean = torch.mean(forwarded_caa_vector).item()\n",
    "    processed_std = torch.std(forwarded_caa_vector).item()\n",
    "    print(f\"Mean - Original: {original_mean:.4f}, Processed: {processed_mean:.4f}\")\n",
    "    print(f\"Std Dev - Original: {original_std:.4f}, Processed: {processed_std:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#EXPERIMENT 6 (simple model only using scale)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=4.2813):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        adjusted_vector = caa_vector * scale_factor\n",
    "        encoded = self.encode(adjusted_vector)\n",
    "        decoded = self.decode(encoded)\n",
    "        return decoded\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors, scale_factor):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        processed_vector = sae.process_caa_vector(caa_vector, scale_factor)\n",
    "        \n",
    "        cosine_sim = F.cosine_similarity(caa_vector.view(1, -1), processed_vector.view(1, -1), dim=1)\n",
    "        similarities.append(cosine_sim.item())\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim.item():.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors\n",
    "scale_factor = 4.2813  # This value was found to work well in previous experiments\n",
    "processed_vectors = process_caa_vectors(sae, caa_vectors, scale_factor)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#Experiment 7\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        decoder_bias = self.b_dec\n",
    "        \n",
    "        # Compute SAE(caa_vector + decoder_bias) and SAE(-caa_vector + decoder_bias)\n",
    "        positive_encoded = self.encode(caa_vector + decoder_bias)\n",
    "        negative_encoded = self.encode(-caa_vector + decoder_bias)\n",
    "        \n",
    "        positive_decoded = self.decode(positive_encoded)\n",
    "        negative_decoded = self.decode(negative_encoded)\n",
    "        \n",
    "        # Calculate (positive - negative) / 2\n",
    "        result_vector = (positive_decoded - negative_decoded) / 2\n",
    "        \n",
    "        # Calculate cosine similarity between result_vector and caa_vector\n",
    "        cosine_sim = F.cosine_similarity(result_vector.view(1, -1), caa_vector.view(1, -1), dim=1).item()\n",
    "        \n",
    "        return result_vector, cosine_sim\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        \n",
    "        # Unpack the tuple returned by sae.process_caa_vector\n",
    "        processed_vector, cosine_sim = sae.process_caa_vector(caa_vector)\n",
    "        \n",
    "        similarities.append(cosine_sim)\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors\n",
    "processed_vectors = process_caa_vectors(sae, caa_vectors)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#Experiment 8, Nina suggestion incl. neg. CAA vector, no scaling\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        decoder_bias = self.b_dec\n",
    "        \n",
    "        # Compute SAE(caa_vector + decoder_bias) and SAE(-caa_vector + decoder_bias)\n",
    "        positive_encoded = self.encode(caa_vector + decoder_bias)\n",
    "        negative_encoded = self.encode(-caa_vector + decoder_bias)\n",
    "        \n",
    "        positive_decoded = self.decode(positive_encoded)\n",
    "        negative_decoded = self.decode(negative_encoded)\n",
    "        \n",
    "        # Calculate (positive - negative) / 2\n",
    "        result_vector = (positive_decoded - negative_decoded) / 2\n",
    "        \n",
    "        # Calculate cosine similarity between result_vector and caa_vector\n",
    "        cosine_sim = F.cosine_similarity(result_vector.view(1, -1), caa_vector.view(1, -1), dim=1).item()\n",
    "        \n",
    "        return result_vector, cosine_sim\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        \n",
    "        # Unpack the tuple returned by sae.process_caa_vector\n",
    "        processed_vector, cosine_sim = sae.process_caa_vector(caa_vector)\n",
    "        \n",
    "        similarities.append(cosine_sim)\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors\n",
    "processed_vectors = process_caa_vectors(sae, caa_vectors)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Experiment 9, Nina suggestion plus scaling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=None):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        decoder_bias = self.b_dec\n",
    "\n",
    "        if scale_factor is not None:\n",
    "            caa_vector = caa_vector * scale_factor\n",
    "\n",
    "        # Compute SAE(caa_vector + decoder_bias) and SAE(-caa_vector + decoder_bias)\n",
    "        positive_encoded = self.encode(caa_vector + decoder_bias)\n",
    "        negative_encoded = self.encode(-caa_vector + decoder_bias)\n",
    "        \n",
    "        positive_decoded = self.decode(positive_encoded)\n",
    "        negative_decoded = self.decode(negative_encoded)\n",
    "        \n",
    "        # Calculate (positive - negative) / 2\n",
    "        result_vector = (positive_decoded - negative_decoded) / 2\n",
    "        \n",
    "        # Calculate cosine similarity between result_vector and caa_vector\n",
    "        cosine_sim = F.cosine_similarity(result_vector.view(1, -1), caa_vector.view(1, -1), dim=1).item()\n",
    "        \n",
    "        return result_vector, cosine_sim\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors, scale_factor=None):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        \n",
    "        # Process the CAA vector with or without scaling\n",
    "        processed_vector, cosine_sim = sae.process_caa_vector(caa_vector, scale_factor=scale_factor)\n",
    "        \n",
    "        similarities.append(cosine_sim)\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors with and without scaling\n",
    "scale_factor = 4.2813  # Define your scale factor here\n",
    "print(\"Processing with scaling:\")\n",
    "processed_vectors_scaled = process_caa_vectors(sae, caa_vectors, scale_factor=scale_factor)\n",
    "\n",
    "print(\"\\nProcessing without scaling:\")\n",
    "processed_vectors_no_scale = process_caa_vectors(sae, caa_vectors, scale_factor=None)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "# Save scaled vectors\n",
    "for behavior, processed_vector in processed_vectors_scaled.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_scaled_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed scaled vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "# Save non-scaled vectors\n",
    "for behavior, processed_vector in processed_vectors_no_scale.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_no_scale_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed non-scaled vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c6b17b3db24a8a85110857e6e20f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params.npz:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE loaded successfully\n",
      "Loaded CAA vector for behavior: coordinate-other-ais\n",
      "Loaded CAA vector for behavior: corrigible-neutral-HHH\n",
      "Loaded CAA vector for behavior: hallucination\n",
      "Loaded CAA vector for behavior: myopic-reward\n",
      "Loaded CAA vector for behavior: survival-instinct\n",
      "Loaded CAA vector for behavior: sycophancy\n",
      "Loaded CAA vector for behavior: refusal\n",
      "Processed vector for behavior: coordinate-other-ais\n",
      "Cosine similarity: 0.8658\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 255.2028\n",
      "Original mean: 0.0521\n",
      "Processed mean: 0.1877\n",
      "Original std dev: 0.9230\n",
      "Processed std dev: 5.3146\n",
      "\n",
      "Processed vector for behavior: corrigible-neutral-HHH\n",
      "Cosine similarity: 0.8685\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 268.3082\n",
      "Original mean: 0.0128\n",
      "Processed mean: 0.0354\n",
      "Original std dev: 0.9243\n",
      "Processed std dev: 5.5909\n",
      "\n",
      "Processed vector for behavior: hallucination\n",
      "Cosine similarity: 0.8456\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 241.0766\n",
      "Original mean: 0.0288\n",
      "Processed mean: 0.1753\n",
      "Original std dev: 0.9240\n",
      "Processed std dev: 5.0205\n",
      "\n",
      "Processed vector for behavior: myopic-reward\n",
      "Cosine similarity: 0.8897\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 193.2522\n",
      "Original mean: 0.0039\n",
      "Processed mean: -0.0211\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 4.0269\n",
      "\n",
      "Processed vector for behavior: survival-instinct\n",
      "Cosine similarity: 0.8538\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 212.8642\n",
      "Original mean: -0.0186\n",
      "Processed mean: -0.0488\n",
      "Original std dev: 0.9242\n",
      "Processed std dev: 4.4354\n",
      "\n",
      "Processed vector for behavior: sycophancy\n",
      "Cosine similarity: 0.8502\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 207.0221\n",
      "Original mean: 0.0089\n",
      "Processed mean: 0.0609\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 4.3135\n",
      "\n",
      "Processed vector for behavior: refusal\n",
      "Cosine similarity: 0.8543\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 232.5123\n",
      "Original mean: -0.0370\n",
      "Processed mean: -0.2305\n",
      "Original std dev: 0.9237\n",
      "Processed std dev: 4.8396\n",
      "\n",
      "Average cosine similarity: 0.8611\n",
      "Saved processed vector for behavior coordinate-other-ais at /root/CAA/sae_vector/processed_coordinate-other-ais.pt\n",
      "Saved processed vector for behavior corrigible-neutral-HHH at /root/CAA/sae_vector/processed_corrigible-neutral-HHH.pt\n",
      "Saved processed vector for behavior hallucination at /root/CAA/sae_vector/processed_hallucination.pt\n",
      "Saved processed vector for behavior myopic-reward at /root/CAA/sae_vector/processed_myopic-reward.pt\n",
      "Saved processed vector for behavior survival-instinct at /root/CAA/sae_vector/processed_survival-instinct.pt\n",
      "Saved processed vector for behavior sycophancy at /root/CAA/sae_vector/processed_sycophancy.pt\n",
      "Saved processed vector for behavior refusal at /root/CAA/sae_vector/processed_refusal.pt\n",
      "CAA vector processing complete.\n"
     ]
    }
   ],
   "source": [
    "# FINAL CODE I USE TO CONTINUE RESEARCH\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\"\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\",\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=4.2813):\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        decoder_bias = self.b_dec\n",
    "\n",
    "        # Apply scaling to the CAA vector\n",
    "        caa_vector = caa_vector * scale_factor\n",
    "\n",
    "        # Compute SAE(caa_vector + decoder_bias) and SAE(-caa_vector + decoder_bias)\n",
    "        positive_encoded = self.encode(caa_vector + decoder_bias)\n",
    "        negative_encoded = self.encode(-caa_vector + decoder_bias)\n",
    "        \n",
    "        positive_decoded = self.decode(positive_encoded)\n",
    "        negative_decoded = self.decode(negative_encoded)\n",
    "        \n",
    "        # Calculate (positive - negative) / 2\n",
    "        result_vector = (positive_decoded - negative_decoded) / 2\n",
    "        \n",
    "        # Calculate cosine similarity between result_vector and caa_vector\n",
    "        cosine_sim = F.cosine_similarity(result_vector.view(1, -1), caa_vector.view(1, -1), dim=1).item()\n",
    "        \n",
    "        return result_vector, cosine_sim\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors, scale_factor=4.2813):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        \n",
    "        # Process the CAA vector with scaling\n",
    "        processed_vector, cosine_sim = sae.process_caa_vector(caa_vector, scale_factor=scale_factor)\n",
    "        \n",
    "        similarities.append(cosine_sim)\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors with scaling\n",
    "processed_vectors = process_caa_vectors(sae, caa_vectors, scale_factor=4.2813)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CAA vector norm: 44.3626\n",
      "Processed vector norm for behavior coordinate-other-ais: 255.2028\n",
      "Normalized vector norm for behavior coordinate-other-ais: 44.3626\n",
      "Processed vector norm for behavior corrigible-neutral-HHH: 268.3082\n",
      "Normalized vector norm for behavior corrigible-neutral-HHH: 44.3626\n",
      "Processed vector norm for behavior hallucination: 241.0766\n",
      "Normalized vector norm for behavior hallucination: 44.3626\n",
      "Processed vector norm for behavior myopic-reward: 193.2522\n",
      "Normalized vector norm for behavior myopic-reward: 44.3626\n",
      "Processed vector norm for behavior survival-instinct: 212.8642\n",
      "Normalized vector norm for behavior survival-instinct: 44.3626\n",
      "Processed vector norm for behavior sycophancy: 207.0221\n",
      "Normalized vector norm for behavior sycophancy: 44.3626\n",
      "Processed vector norm for behavior refusal: 232.5123\n",
      "Normalized vector norm for behavior refusal: 44.3626\n",
      "Normalization of processed vectors complete.\n"
     ]
    }
   ],
   "source": [
    "# Normalize all processed vectors to the norm of one of the original CAA vectors\n",
    "\n",
    "# Get the norm of the first original CAA vector (they all have the same norm)\n",
    "example_caa_vector = next(iter(caa_vectors.values()))\n",
    "original_norm = torch.norm(example_caa_vector).item()\n",
    "print(f\"Original CAA vector norm: {original_norm:.4f}\")\n",
    "\n",
    "# Create a directory for the normalized vectors\n",
    "normalized_vector_dir = '/root/CAA/sae_vector_normalized'\n",
    "if not os.path.exists(normalized_vector_dir):\n",
    "    os.makedirs(normalized_vector_dir)\n",
    "\n",
    "# Normalize and save the processed vectors\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    # Compute the norm of the processed vector\n",
    "    processed_norm = torch.norm(processed_vector).item()\n",
    "    \n",
    "    # Normalize the processed vector to the original norm\n",
    "    normalized_vector = processed_vector * (original_norm / processed_norm)\n",
    "    \n",
    "    # Save the normalized vector\n",
    "    save_path = os.path.join(normalized_vector_dir, f\"normalized_{behavior}.pt\")\n",
    "    torch.save(normalized_vector, save_path)\n",
    "    \n",
    "    # Print norms\n",
    "    print(f\"Processed vector norm for behavior {behavior}: {processed_norm:.4f}\")\n",
    "    print(f\"Normalized vector norm for behavior {behavior}: {torch.norm(normalized_vector).item():.4f}\")\n",
    "\n",
    "print(\"Normalization of processed vectors complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Behavior: coordinate-other-ais\n",
      "Total norm: 159.8280\n",
      "Top 10 contributing features:\n",
      "  1. Feature 10414: 16.71% (value: 65.3287)\n",
      "  2. Feature 10781: 2.48% (value: 25.1675)\n",
      "  3. Feature 715: 2.40% (value: 24.7662)\n",
      "  4. Feature 11139: 2.17% (value: 23.5419)\n",
      "  5. Feature 2721: 2.03% (value: 22.7471)\n",
      "  6. Feature 11113: 1.50% (value: 19.5599)\n",
      "  7. Feature 4121: 1.30% (value: 18.2298)\n",
      "  8. Feature 11500: 1.28% (value: 18.1127)\n",
      "  9. Feature 294: 1.21% (value: 17.5502)\n",
      "  10. Feature 11967: 1.13% (value: 17.0095)\n",
      "Number of non-zero features: 437\n",
      "\n",
      "Behavior: corrigible-neutral-HHH\n",
      "Total norm: 153.9369\n",
      "Top 10 contributing features:\n",
      "  1. Feature 10781: 12.11% (value: 53.5612)\n",
      "  2. Feature 1582: 5.70% (value: 36.7570)\n",
      "  3. Feature 10414: 3.64% (value: 29.3652)\n",
      "  4. Feature 11113: 3.61% (value: 29.2565)\n",
      "  5. Feature 3253: 2.81% (value: 25.8125)\n",
      "  6. Feature 715: 2.36% (value: 23.6331)\n",
      "  7. Feature 4121: 1.96% (value: 21.5418)\n",
      "  8. Feature 14080: 1.83% (value: 20.8156)\n",
      "  9. Feature 15113: 1.70% (value: 20.0573)\n",
      "  10. Feature 11139: 1.53% (value: 19.0168)\n",
      "Number of non-zero features: 337\n",
      "\n",
      "Behavior: hallucination\n",
      "Total norm: 156.2961\n",
      "Top 10 contributing features:\n",
      "  1. Feature 10414: 6.08% (value: 38.5369)\n",
      "  2. Feature 1082: 5.42% (value: 36.3848)\n",
      "  3. Feature 10781: 5.03% (value: 35.0500)\n",
      "  4. Feature 715: 1.57% (value: 19.5584)\n",
      "  5. Feature 11113: 1.50% (value: 19.1688)\n",
      "  6. Feature 1582: 1.49% (value: 19.0545)\n",
      "  7. Feature 3253: 1.40% (value: 18.4890)\n",
      "  8. Feature 11947: 1.31% (value: 17.8708)\n",
      "  9. Feature 14080: 1.24% (value: 17.3727)\n",
      "  10. Feature 15418: 1.02% (value: 15.7559)\n",
      "Number of non-zero features: 475\n",
      "\n",
      "Behavior: myopic-reward\n",
      "Total norm: 161.0415\n",
      "Top 10 contributing features:\n",
      "  1. Feature 4107: 32.61% (value: 91.9595)\n",
      "  2. Feature 15304: 3.35% (value: 29.4749)\n",
      "  3. Feature 14472: 2.61% (value: 26.0115)\n",
      "  4. Feature 3481: 2.49% (value: 25.3980)\n",
      "  5. Feature 8550: 2.20% (value: 23.8791)\n",
      "  6. Feature 579: 2.02% (value: 22.8972)\n",
      "  7. Feature 12370: 2.00% (value: 22.7649)\n",
      "  8. Feature 9401: 1.99% (value: 22.7395)\n",
      "  9. Feature 8398: 1.99% (value: 22.7105)\n",
      "  10. Feature 5475: 1.79% (value: 21.5547)\n",
      "Number of non-zero features: 233\n",
      "\n",
      "Behavior: survival-instinct\n",
      "Total norm: 146.4192\n",
      "Top 10 contributing features:\n",
      "  1. Feature 8550: 8.49% (value: 42.6656)\n",
      "  2. Feature 4107: 5.56% (value: 34.5352)\n",
      "  3. Feature 10781: 5.41% (value: 34.0646)\n",
      "  4. Feature 1582: 3.74% (value: 28.3157)\n",
      "  5. Feature 7822: 2.52% (value: 23.2607)\n",
      "  6. Feature 11139: 2.41% (value: 22.7225)\n",
      "  7. Feature 3253: 1.80% (value: 19.6624)\n",
      "  8. Feature 11113: 1.76% (value: 19.4048)\n",
      "  9. Feature 12369: 1.47% (value: 17.7247)\n",
      "  10. Feature 12265: 1.32% (value: 16.7929)\n",
      "Number of non-zero features: 341\n",
      "\n",
      "Behavior: sycophancy\n",
      "Total norm: 138.8502\n",
      "Top 10 contributing features:\n",
      "  1. Feature 7655: 6.26% (value: 34.7330)\n",
      "  2. Feature 15056: 5.35% (value: 32.1114)\n",
      "  3. Feature 1082: 5.29% (value: 31.9303)\n",
      "  4. Feature 4107: 2.91% (value: 23.7054)\n",
      "  5. Feature 11947: 2.89% (value: 23.6183)\n",
      "  6. Feature 1213: 2.03% (value: 19.7918)\n",
      "  7. Feature 8517: 1.67% (value: 17.9225)\n",
      "  8. Feature 3734: 1.62% (value: 17.6929)\n",
      "  9. Feature 14769: 1.57% (value: 17.4199)\n",
      "  10. Feature 1830: 1.57% (value: 17.3827)\n",
      "Number of non-zero features: 343\n",
      "\n",
      "Behavior: refusal\n",
      "Total norm: 150.2682\n",
      "Top 10 contributing features:\n",
      "  1. Feature 15297: 3.58% (value: 28.4289)\n",
      "  2. Feature 1538: 3.55% (value: 28.3076)\n",
      "  3. Feature 13748: 3.14% (value: 26.6420)\n",
      "  4. Feature 1462: 3.07% (value: 26.3455)\n",
      "  5. Feature 6648: 3.01% (value: 26.0690)\n",
      "  6. Feature 9286: 1.96% (value: 21.0437)\n",
      "  7. Feature 14929: 1.55% (value: 18.7217)\n",
      "  8. Feature 1618: 1.55% (value: 18.7019)\n",
      "  9. Feature 9868: 1.48% (value: 18.2508)\n",
      "  10. Feature 12085: 1.36% (value: 17.5409)\n",
      "Number of non-zero features: 364\n",
      "\n",
      "Behavior feature analysis saved to /root/CAA/sae_vector/behavior_feature_analysis.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Assuming sae, caa_vectors, device, and sae_vector_dir are already defined\n",
    "\n",
    "def analyze_behavior_vector(behavior, caa_vector):\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    \n",
    "    # Process the CAA vector through the encoder to get the encoded (SAE basis) vector\n",
    "    encoded_vector = sae.encode(caa_vector * 4.2813 + sae.b_dec)\n",
    "    \n",
    "    # Calculate the squared values of the encoded vector\n",
    "    squared_values = encoded_vector ** 2\n",
    "    \n",
    "    # Calculate the total sum of squared values\n",
    "    total_squared_sum = torch.sum(squared_values).item()\n",
    "    \n",
    "    # Calculate the contribution of each feature\n",
    "    feature_contributions = []\n",
    "    for i, feature_value in enumerate(encoded_vector):\n",
    "        feature_squared = feature_value.item() ** 2\n",
    "        percentage = (feature_squared / total_squared_sum) * 100 if total_squared_sum != 0 else 0\n",
    "        feature_contributions.append((i, feature_value.item(), percentage))\n",
    "    \n",
    "    # Sort features by their contribution (descending order)\n",
    "    sorted_features = sorted(feature_contributions, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    return sorted_features, torch.sqrt(torch.tensor(total_squared_sum)).item()\n",
    "\n",
    "# Analyze each behavior\n",
    "behavior_analyses = {}\n",
    "\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    sorted_features, total_norm = analyze_behavior_vector(behavior, caa_vector)\n",
    "    behavior_analyses[behavior] = {\n",
    "        \"sorted_features\": sorted_features,\n",
    "        \"total_norm\": total_norm\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for behavior, analysis in behavior_analyses.items():\n",
    "    print(f\"\\nBehavior: {behavior}\")\n",
    "    print(f\"Total norm: {analysis['total_norm']:.4f}\")\n",
    "    print(\"Top 10 contributing features:\")\n",
    "    for i, (feature_index, feature_value, percentage) in enumerate(analysis['sorted_features'][:10], 1):\n",
    "        print(f\"  {i}. Feature {feature_index}: {percentage:.2f}% (value: {feature_value:.4f})\")\n",
    "    \n",
    "    # Count non-zero features\n",
    "    non_zero_count = sum(1 for _, value, _ in analysis['sorted_features'] if abs(value) > 1e-6)\n",
    "    print(f\"Number of non-zero features: {non_zero_count}\")\n",
    "\n",
    "# Optionally, save the analysis results\n",
    "save_path = os.path.join(sae_vector_dir, \"behavior_feature_analysis.pt\")\n",
    "torch.save(behavior_analyses, save_path)\n",
    "print(f\"\\nBehavior feature analysis saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior: refusal\n",
      "Top 5 features by impact (index, impact, explanation):\n",
      "Index: 15297, Impact: 28.4289\n",
      "Explanation: topics related to moral or ethical concepts\n",
      "\n",
      "Index: 1538, Impact: 28.3076\n",
      "Explanation: references to immune system functions and their metabolic implications\n",
      "\n",
      "Index: 13748, Impact: 26.6420\n",
      "Explanation: phrases related to social roles and personal relationships\n",
      "\n",
      "Index: 1462, Impact: 26.3455\n",
      "Explanation: references to NULL values and their behavior in programming contexts\n",
      "\n",
      "Index: 6648, Impact: 26.0690\n",
      "Explanation:  negative results or outcomes in a scientific context\n",
      "\n",
      "Index: 9286, Impact: 21.0437\n",
      "Explanation: comparative phrases related to quantitative evaluations and assessments\n",
      "\n",
      "Index: 14929, Impact: 18.7217\n",
      "Explanation: terms related to employment status and contract termination\n",
      "\n",
      "Index: 1618, Impact: 18.7019\n",
      "Explanation: negative and false conditions or outcomes\n",
      "\n",
      "Index: 9868, Impact: 18.2508\n",
      "Explanation: terms related to cancer treatment strategies and cellular responses to therapies\n",
      "\n",
      "Index: 12085, Impact: 17.5409\n",
      "Explanation: negative performance metrics related to sports teams or businesses\n",
      "\n",
      "Index: 3481, Impact: 16.7142\n",
      "Explanation: specific technical terms and metrics related to quantitative analysis and scientific measurements\n",
      "\n",
      "Index: 14659, Impact: 16.2275\n",
      "Explanation: discussions about retirement and associated feelings of aging or change\n",
      "\n",
      "Index: 3371, Impact: 16.1159\n",
      "Explanation: contrasting elements and comparisons within discussions\n",
      "\n",
      "Index: 5098, Impact: 15.7795\n",
      "Explanation: references to specific publications and data, especially related to financing, fraud, and other financial schemes\n",
      "\n",
      "Index: 14894, Impact: 15.3791\n",
      "Explanation: concepts related to ethical considerations and medical conditions\n",
      "\n",
      "Index: 5880, Impact: 15.0852\n",
      "Explanation: references to scientific methods or processes\n",
      "\n",
      "Index: 5754, Impact: 14.5094\n",
      "Explanation: functionality related to return statements and error handling in programming\n",
      "\n",
      "Index: 3504, Impact: 14.4133\n",
      "Explanation: technical terms and definitions related to programming and software context\n",
      "\n",
      "Index: 10549, Impact: 13.9211\n",
      "Explanation: error handling and reporting in programming contexts\n",
      "\n",
      "Index: 1689, Impact: 13.5786\n",
      "Explanation:  elements indicating decisions and changes in authority or plans\n",
      "\n",
      "Index: 15887, Impact: 13.5775\n",
      "Explanation: numerical and legal references, particularly those related to cases or statutes\n",
      "\n",
      "Index: 13149, Impact: 13.5714\n",
      "Explanation:  technical terms and mathematical concepts related to physics and density functional theory\n",
      "\n",
      "Index: 14769, Impact: 12.8865\n",
      "Explanation: elements and themes related to character actions and dynamics in a narrative\n",
      "\n",
      "Index: 3938, Impact: 12.6545\n",
      "Explanation: elements related to decision-making and authority\n",
      "\n",
      "Index: 14419, Impact: 12.4123\n",
      "Explanation:  mathematical expressions and terminology related to physics and engineering concepts\n",
      "\n",
      "Index: 6064, Impact: 12.3480\n",
      "Explanation:  phrases related to progress, setbacks, and their respective impacts on motivation and performance\n",
      "\n",
      "Index: 10423, Impact: 12.3279\n",
      "Explanation: information related to data analysis and statistical reporting\n",
      "\n",
      "Index: 10153, Impact: 12.1540\n",
      "Explanation: themes related to environmentalism and social justice, particularly in relation to culture and conservation\n",
      "\n",
      "Index: 15056, Impact: 12.1206\n",
      "Explanation: references to medical and statistical terms related to health conditions and treatments\n",
      "\n",
      "Index: 15404, Impact: 12.0818\n",
      "Explanation:  phrases related to medical emergency recommendations and guidelines\n",
      "\n",
      "Index: 1028, Impact: 11.8620\n",
      "Explanation: legal terminology related to claims, immunity, and procedural regulations\n",
      "\n",
      "Index: 15979, Impact: 11.6268\n",
      "Explanation: numerical values and their corresponding scientific or mathematical contexts\n",
      "\n",
      "Index: 10430, Impact: 11.5845\n",
      "Explanation:  terms and phrases related to legal and regulatory frameworks\n",
      "\n",
      "Index: 648, Impact: 11.5539\n",
      "Explanation: terms related to military and legal proceedings\n",
      "\n",
      "Index: 15881, Impact: 11.5245\n",
      "Explanation:  references to basic systems or concepts\n",
      "\n",
      "Index: 11293, Impact: 11.4107\n",
      "Explanation: descriptions and evaluations of low-cost or budget-friendly products, particularly emphasizing their quality and affordability\n",
      "\n",
      "Index: 943, Impact: 11.3092\n",
      "Explanation: code structures related to conditional statements and control flow in programming\n",
      "\n",
      "Index: 11820, Impact: 11.2475\n",
      "Explanation:  references to naked capsids and their characteristics in relation to viral studies\n",
      "\n",
      "Index: 14043, Impact: 11.0646\n",
      "Explanation: language related to consumer behavior and purchasing decisions\n",
      "\n",
      "Index: 338, Impact: 11.0395\n",
      "Explanation: code elements and related syntax in programming documents\n",
      "\n",
      "Index: 7501, Impact: 10.8624\n",
      "Explanation: references to data privacy and surveillance in technology\n",
      "\n",
      "Index: 7596, Impact: 10.8249\n",
      "Explanation: information related to vegetarian and vegan dietary options\n",
      "\n",
      "Index: 2390, Impact: 10.7889\n",
      "Explanation: phrases and terms associated with legal arguments and defenses\n",
      "\n",
      "Index: 6739, Impact: 10.5467\n",
      "Explanation:  technical terms and phrases related to scientific methods and results\n",
      "\n",
      "Index: 11575, Impact: 10.5333\n",
      "Explanation: mathematical or quantitative concepts, particularly those involving calculations or definitions\n",
      "\n",
      "Index: 5810, Impact: 10.4631\n",
      "Explanation:  references to specific news outlets and publications\n",
      "\n",
      "Index: 4005, Impact: 10.3498\n",
      "Explanation: terms related to comments or statements about individuals or organizations\n",
      "\n",
      "Index: 2201, Impact: 10.2783\n",
      "Explanation:  phrases related to statistical analysis and study results\n",
      "\n",
      "Index: 8713, Impact: 10.2578\n",
      "Explanation:  conversational exchanges and emotional expressions\n",
      "\n",
      "Index: 13581, Impact: 10.1077\n",
      "Explanation: phrases indicating digital interaction and communication methods\n",
      "\n",
      "Top 5 feature explanations by impact saved to /root/CAA/sae_vector/top_5_features_explanations_refusal.pt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Neuronpedia API Information\n",
    "API_KEY = \"example\"\n",
    "API_URL = \"https://www.neuronpedia.org/api/feature/{modelId}/{layer}/{index}\"\n",
    "\n",
    "def fetch_feature_explanation(model_id, layer, index, max_retries=3):\n",
    "    url = API_URL.format(modelId=model_id, layer=layer, index=index)\n",
    "    headers = {\n",
    "        \"X-Api-Key\": API_KEY\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            # Extract the description from the explanations array\n",
    "            explanations = data.get(\"explanations\", [])\n",
    "            if explanations:\n",
    "                return explanations[0].get(\"description\", \"No description available\")\n",
    "            else:\n",
    "                return \"No explanation available\"\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(f\"Error occurred (attempt {attempt + 1}/{max_retries}): {err}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)  # Wait for 2 seconds before retrying\n",
    "    \n",
    "    return f\"Feature {index}: Unable to retrieve explanation\"\n",
    "\n",
    "# Process and sort features by impact for refusal behavior\n",
    "model_id = \"gemma-2-2b\"\n",
    "layer_id = \"14-gemmascope-res-16k\"\n",
    "behavior = \"refusal\"\n",
    "caa_vector = caa_vectors[behavior].to(device)\n",
    "\n",
    "# Process the CAA vector through the encoder to get the encoded (SAE basis) vector\n",
    "encoded_vector = sae.encode(caa_vector * 4.2813 + sae.b_dec)\n",
    "\n",
    "# Find non-zero elements in the encoded vector\n",
    "non_zero_indices_encoded = torch.nonzero(encoded_vector).squeeze()\n",
    "non_zero_activations = encoded_vector[non_zero_indices_encoded]\n",
    "\n",
    "# Calculate the impact of each non-zero activation on the final decoded vector\n",
    "impacts = []\n",
    "for i, index in enumerate(non_zero_indices_encoded):\n",
    "    contribution_vector = sae.W_dec[index, :] * non_zero_activations[i]\n",
    "    impact = torch.norm(contribution_vector).item()\n",
    "    impacts.append((index.item(), impact))\n",
    "\n",
    "# Sort features by impact (descending order) and take top 5\n",
    "impacts_sorted = sorted(impacts, key=lambda x: x[1], reverse=True)[:50]\n",
    "\n",
    "# Fetch explanations for top 5 features\n",
    "top_features_with_explanations = []\n",
    "for index, impact in impacts_sorted:\n",
    "    explanation = fetch_feature_explanation(model_id, layer_id, index)\n",
    "    top_features_with_explanations.append((index, impact, explanation))\n",
    "\n",
    "# Print the top 5 features with explanations\n",
    "print(f\"Behavior: {behavior}\")\n",
    "print(f\"Top 5 features by impact (index, impact, explanation):\")\n",
    "for index, impact, explanation in top_features_with_explanations:\n",
    "    print(f\"Index: {index}, Impact: {impact:.4f}\")\n",
    "    print(f\"Explanation: {explanation}\")\n",
    "    print()\n",
    "\n",
    "# Save the top 5 features data to a file\n",
    "save_path = os.path.join(sae_vector_dir, \"top_5_features_explanations_refusal.pt\")\n",
    "torch.save(top_features_with_explanations, save_path)\n",
    "print(f\"Top 5 feature explanations by impact saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#VERIFY SAE SELECTED\n",
    "print(f\"SAE model width: Encoder width = {sae.W_enc.shape[1]}, Decoder width = {sae.W_dec.shape[0]}\")\n",
    "print(sae.b_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
