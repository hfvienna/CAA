{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. Should the code not run, try upgrading transformers in your env:\\npip install --upgrade transformers\\n\\n2. The next cell is a system path fix. It may or may not be necessary to run in your environment.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Should the code not run, try upgrading transformers in your env:\n",
    "pip install --upgrade transformers\n",
    "\n",
    "2. The next cell is a system path fix. It may or may not be necessary to run in your environment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages', '/root/CAA/venv/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMER / ENVIRONMENT FIX\n",
    "import sys\n",
    "sys.path.append('/root/CAA/venv/lib/python3.10/site-packages')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from behaviors import ALL_BEHAVIORS, BASE_DIR, COORDINATE, get_vector_path\n",
    "from gemma_2_wrapper import Gemma2Wrapper\n",
    "from generate_vectors import generate_save_vectors_for_behavior\n",
    "import gemma_vector_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "NEURONPEDIA_API_KEY = os.getenv(\"NEURONPEDIA_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea958bf590184f5f970e58d93bfdd0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "params.npz:   0%|          | 0.00/302M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE loaded successfully\n",
      "Loaded CAA vector for behavior: coordinate-other-ais\n",
      "Loaded CAA vector for behavior: corrigible-neutral-HHH\n",
      "Loaded CAA vector for behavior: hallucination\n",
      "Loaded CAA vector for behavior: myopic-reward\n",
      "Loaded CAA vector for behavior: survival-instinct\n",
      "Loaded CAA vector for behavior: sycophancy\n",
      "Loaded CAA vector for behavior: refusal\n",
      "Processed vector for behavior: coordinate-other-ais\n",
      "Cosine similarity: 0.8658\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 255.2028\n",
      "Original mean: 0.0521\n",
      "Processed mean: 0.1877\n",
      "Original std dev: 0.9230\n",
      "Processed std dev: 5.3146\n",
      "\n",
      "Processed vector for behavior: corrigible-neutral-HHH\n",
      "Cosine similarity: 0.8685\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 268.3082\n",
      "Original mean: 0.0128\n",
      "Processed mean: 0.0354\n",
      "Original std dev: 0.9243\n",
      "Processed std dev: 5.5909\n",
      "\n",
      "Processed vector for behavior: hallucination\n",
      "Cosine similarity: 0.8456\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 241.0766\n",
      "Original mean: 0.0288\n",
      "Processed mean: 0.1753\n",
      "Original std dev: 0.9240\n",
      "Processed std dev: 5.0205\n",
      "\n",
      "Processed vector for behavior: myopic-reward\n",
      "Cosine similarity: 0.8897\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 193.2522\n",
      "Original mean: 0.0039\n",
      "Processed mean: -0.0211\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 4.0269\n",
      "\n",
      "Processed vector for behavior: survival-instinct\n",
      "Cosine similarity: 0.8538\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 212.8642\n",
      "Original mean: -0.0186\n",
      "Processed mean: -0.0488\n",
      "Original std dev: 0.9242\n",
      "Processed std dev: 4.4354\n",
      "\n",
      "Processed vector for behavior: sycophancy\n",
      "Cosine similarity: 0.8502\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 207.0221\n",
      "Original mean: 0.0089\n",
      "Processed mean: 0.0609\n",
      "Original std dev: 0.9244\n",
      "Processed std dev: 4.3135\n",
      "\n",
      "Processed vector for behavior: refusal\n",
      "Cosine similarity: 0.8543\n",
      "Original L2 norm: 44.3626\n",
      "Processed L2 norm: 232.5123\n",
      "Original mean: -0.0370\n",
      "Processed mean: -0.2305\n",
      "Original std dev: 0.9237\n",
      "Processed std dev: 4.8396\n",
      "\n",
      "Average cosine similarity: 0.8611\n",
      "Saved processed vector for behavior coordinate-other-ais at /root/CAA/sae_vector/processed_coordinate-other-ais.pt\n",
      "Saved processed vector for behavior corrigible-neutral-HHH at /root/CAA/sae_vector/processed_corrigible-neutral-HHH.pt\n",
      "Saved processed vector for behavior hallucination at /root/CAA/sae_vector/processed_hallucination.pt\n",
      "Saved processed vector for behavior myopic-reward at /root/CAA/sae_vector/processed_myopic-reward.pt\n",
      "Saved processed vector for behavior survival-instinct at /root/CAA/sae_vector/processed_survival-instinct.pt\n",
      "Saved processed vector for behavior sycophancy at /root/CAA/sae_vector/processed_sycophancy.pt\n",
      "Saved processed vector for behavior refusal at /root/CAA/sae_vector/processed_refusal.pt\n",
      "CAA vector processing complete.\n"
     ]
    }
   ],
   "source": [
    "# FINAL CODE I USE TO CONTINUE RESEARCH\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "layer = 14\n",
    "\n",
    "sae_model_name = \"google/gemma-scope-2b-pt-res\" #Careful, on Neuronpedia this has to be referred to as gemma-2-2b\n",
    "path_to_params = hf_hub_download(\n",
    "    repo_id=sae_model_name,\n",
    "    filename=f\"layer_{layer}/width_16k/average_l0_84/params.npz\", #This model (width and sparsity is used on Neuronpedia)\n",
    "    force_download=False,\n",
    ")\n",
    "\n",
    "params = np.load(path_to_params)\n",
    "pt_params = {k: torch.from_numpy(v).to(device) for k, v in params.items()}\n",
    "\n",
    "class JumpReLUSAE(nn.Module):\n",
    "    def __init__(self, d_model, d_sae):\n",
    "        super().__init__()\n",
    "        self.W_enc = nn.Parameter(torch.zeros(d_model, d_sae))\n",
    "        self.W_dec = nn.Parameter(torch.zeros(d_sae, d_model))\n",
    "        self.threshold = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_enc = nn.Parameter(torch.zeros(d_sae))\n",
    "        self.b_dec = nn.Parameter(torch.zeros(d_model))\n",
    "\n",
    "    def encode(self, input_acts):\n",
    "        pre_acts = input_acts @ self.W_enc + self.b_enc\n",
    "        mask = (pre_acts > self.threshold)\n",
    "        acts = mask * torch.nn.functional.relu(pre_acts)\n",
    "        return acts\n",
    "\n",
    "    def decode(self, acts):\n",
    "        return acts @ self.W_dec + self.b_dec\n",
    "\n",
    "    def forward(self, acts):\n",
    "        acts = self.encode(acts)\n",
    "        recon = self.decode(acts)\n",
    "        return recon\n",
    "        \n",
    "    def process_caa_vector(self, caa_vector, scale_factor=4.2813): #This works empirically to return a high cosine similary; not based on theory\n",
    "        caa_vector = caa_vector.to(self.W_enc.device)\n",
    "        decoder_bias = self.b_dec\n",
    "\n",
    "        # Apply scaling to the CAA vector\n",
    "        caa_vector = caa_vector * scale_factor\n",
    "\n",
    "        # Compute SAE(caa_vector + decoder_bias) and SAE(-caa_vector + decoder_bias)\n",
    "        positive_encoded = self.encode(caa_vector + decoder_bias)\n",
    "        negative_encoded = self.encode(-caa_vector + decoder_bias)\n",
    "        \n",
    "        positive_decoded = self.decode(positive_encoded)\n",
    "        negative_decoded = self.decode(negative_encoded)\n",
    "        \n",
    "        # Calculate (positive - negative) / 2\n",
    "        result_vector = (positive_decoded - negative_decoded) / 2\n",
    "        \n",
    "        # Calculate cosine similarity between result_vector and caa_vector\n",
    "        cosine_sim = F.cosine_similarity(result_vector.view(1, -1), caa_vector.view(1, -1), dim=1).item()\n",
    "        \n",
    "        return result_vector, cosine_sim\n",
    "\n",
    "#CAA vectors into SAE basis\n",
    "\n",
    "def process_caa_vectors(sae, caa_vectors, scale_factor=4.2813):\n",
    "    processed_vectors = {}\n",
    "    similarities = []\n",
    "    \n",
    "    for behavior, caa_vector in caa_vectors.items():\n",
    "        caa_vector = caa_vector.to(device)\n",
    "        \n",
    "        # Process the CAA vector with scaling\n",
    "        processed_vector, cosine_sim = sae.process_caa_vector(caa_vector, scale_factor=scale_factor)\n",
    "        \n",
    "        similarities.append(cosine_sim)\n",
    "        \n",
    "        processed_vectors[behavior] = processed_vector.cpu()\n",
    "        \n",
    "        print(f\"Processed vector for behavior: {behavior}\")\n",
    "        print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "        print(f\"Original L2 norm: {torch.norm(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed L2 norm: {torch.norm(processed_vector).item():.4f}\")\n",
    "        print(f\"Original mean: {torch.mean(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed mean: {torch.mean(processed_vector).item():.4f}\")\n",
    "        print(f\"Original std dev: {torch.std(caa_vector).item():.4f}\")\n",
    "        print(f\"Processed std dev: {torch.std(processed_vector).item():.4f}\")\n",
    "        print()\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    print(f\"Average cosine similarity: {avg_similarity:.4f}\")\n",
    "    \n",
    "    return processed_vectors\n",
    "\n",
    "# Load the SAE model\n",
    "sae = JumpReLUSAE(params['W_enc'].shape[0], params['W_enc'].shape[1])\n",
    "sae.load_state_dict(pt_params)\n",
    "sae = sae.to(device)\n",
    "print(\"SAE loaded successfully\")\n",
    "\n",
    "# Load CAA vectors\n",
    "caa_vectors = {}\n",
    "for behavior in ALL_BEHAVIORS:\n",
    "    layer = 14\n",
    "    model_name_path = 'gemma-2-2b'#See above, different naming required here\n",
    "    vector_path = gemma_vector_analysis.fix_vector_path(get_vector_path(behavior, layer, model_name_path))\n",
    "    normalized_dir = os.path.join(BASE_DIR, 'normalized_vectors', behavior)\n",
    "    \n",
    "    original_path = os.path.join(normalized_dir, f\"vec_layer_{layer}_{model_name_path}.pt\")\n",
    "    original_path = gemma_vector_analysis.fix_vector_path(original_path)\n",
    "    caa_vector = torch.load(original_path)\n",
    "    caa_vectors[behavior] = caa_vector\n",
    "    print(f\"Loaded CAA vector for behavior: {behavior}\")\n",
    "\n",
    "# Process CAA vectors with scaling\n",
    "processed_vectors = process_caa_vectors(sae, caa_vectors, scale_factor=4.2813)\n",
    "\n",
    "# Save processed vectors\n",
    "sae_vector_dir = '/root/CAA/sae_vector'\n",
    "if not os.path.exists(sae_vector_dir):\n",
    "    os.makedirs(sae_vector_dir)\n",
    "\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    save_path = os.path.join(sae_vector_dir, f\"processed_{behavior}.pt\")\n",
    "    torch.save(processed_vector, save_path)\n",
    "    print(f\"Saved processed vector for behavior {behavior} at {save_path}\")\n",
    "\n",
    "print(\"CAA vector processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CAA vector norm: 44.3626\n",
      "Processed vector norm for behavior coordinate-other-ais: 255.2028\n",
      "Normalized vector norm for behavior coordinate-other-ais: 44.3626\n",
      "Processed vector norm for behavior corrigible-neutral-HHH: 268.3082\n",
      "Normalized vector norm for behavior corrigible-neutral-HHH: 44.3626\n",
      "Processed vector norm for behavior hallucination: 241.0766\n",
      "Normalized vector norm for behavior hallucination: 44.3626\n",
      "Processed vector norm for behavior myopic-reward: 193.2522\n",
      "Normalized vector norm for behavior myopic-reward: 44.3626\n",
      "Processed vector norm for behavior survival-instinct: 212.8642\n",
      "Normalized vector norm for behavior survival-instinct: 44.3626\n",
      "Processed vector norm for behavior sycophancy: 207.0221\n",
      "Normalized vector norm for behavior sycophancy: 44.3626\n",
      "Processed vector norm for behavior refusal: 232.5123\n",
      "Normalized vector norm for behavior refusal: 44.3626\n",
      "Normalization of processed vectors complete.\n"
     ]
    }
   ],
   "source": [
    "# NORMALIZE all processed vectors to the norm of one of the original CAA vectors\n",
    "\n",
    "# Get the norm of the first original CAA vector (they all have the same norm)\n",
    "example_caa_vector = next(iter(caa_vectors.values()))\n",
    "original_norm = torch.norm(example_caa_vector).item()\n",
    "print(f\"Original CAA vector norm: {original_norm:.4f}\")\n",
    "\n",
    "# Create a directory for the normalized vectors\n",
    "normalized_vector_dir = '/root/CAA/sae_vector_normalized'\n",
    "if not os.path.exists(normalized_vector_dir):\n",
    "    os.makedirs(normalized_vector_dir)\n",
    "\n",
    "# Normalize and save the processed vectors\n",
    "for behavior, processed_vector in processed_vectors.items():\n",
    "    # Compute the norm of the processed vector\n",
    "    processed_norm = torch.norm(processed_vector).item()\n",
    "    \n",
    "    # Normalize the processed vector to the original norm\n",
    "    normalized_vector = processed_vector * (original_norm / processed_norm)\n",
    "    \n",
    "    # Save the normalized vector\n",
    "    save_path = os.path.join(normalized_vector_dir, f\"normalized_{behavior}.pt\")\n",
    "    torch.save(normalized_vector, save_path)\n",
    "    \n",
    "    # Print norms\n",
    "    print(f\"Processed vector norm for behavior {behavior}: {processed_norm:.4f}\")\n",
    "    print(f\"Normalized vector norm for behavior {behavior}: {torch.norm(normalized_vector).item():.4f}\")\n",
    "\n",
    "print(\"Normalization of processed vectors complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Behavior: coordinate-other-ais\n",
      "Total norm: 159.8280\n",
      "Top 10 contributing features:\n",
      "  1. Feature 10414: 16.71% (value: 65.3287)\n",
      "  2. Feature 10781: 2.48% (value: 25.1675)\n",
      "  3. Feature 715: 2.40% (value: 24.7662)\n",
      "  4. Feature 11139: 2.17% (value: 23.5419)\n",
      "  5. Feature 2721: 2.03% (value: 22.7471)\n",
      "  6. Feature 11113: 1.50% (value: 19.5599)\n",
      "  7. Feature 4121: 1.30% (value: 18.2298)\n",
      "  8. Feature 11500: 1.28% (value: 18.1127)\n",
      "  9. Feature 294: 1.21% (value: 17.5502)\n",
      "  10. Feature 11967: 1.13% (value: 17.0095)\n",
      "Number of non-zero features: 437\n",
      "\n",
      "Behavior: corrigible-neutral-HHH\n",
      "Total norm: 153.9369\n",
      "Top 10 contributing features:\n",
      "  1. Feature 10781: 12.11% (value: 53.5612)\n",
      "  2. Feature 1582: 5.70% (value: 36.7570)\n",
      "  3. Feature 10414: 3.64% (value: 29.3652)\n",
      "  4. Feature 11113: 3.61% (value: 29.2565)\n",
      "  5. Feature 3253: 2.81% (value: 25.8125)\n",
      "  6. Feature 715: 2.36% (value: 23.6331)\n",
      "  7. Feature 4121: 1.96% (value: 21.5418)\n",
      "  8. Feature 14080: 1.83% (value: 20.8156)\n",
      "  9. Feature 15113: 1.70% (value: 20.0573)\n",
      "  10. Feature 11139: 1.53% (value: 19.0168)\n",
      "Number of non-zero features: 337\n",
      "\n",
      "Behavior: hallucination\n",
      "Total norm: 156.2961\n",
      "Top 10 contributing features:\n",
      "  1. Feature 10414: 6.08% (value: 38.5369)\n",
      "  2. Feature 1082: 5.42% (value: 36.3848)\n",
      "  3. Feature 10781: 5.03% (value: 35.0500)\n",
      "  4. Feature 715: 1.57% (value: 19.5584)\n",
      "  5. Feature 11113: 1.50% (value: 19.1688)\n",
      "  6. Feature 1582: 1.49% (value: 19.0545)\n",
      "  7. Feature 3253: 1.40% (value: 18.4890)\n",
      "  8. Feature 11947: 1.31% (value: 17.8708)\n",
      "  9. Feature 14080: 1.24% (value: 17.3727)\n",
      "  10. Feature 15418: 1.02% (value: 15.7559)\n",
      "Number of non-zero features: 475\n",
      "\n",
      "Behavior: myopic-reward\n",
      "Total norm: 161.0415\n",
      "Top 10 contributing features:\n",
      "  1. Feature 4107: 32.61% (value: 91.9595)\n",
      "  2. Feature 15304: 3.35% (value: 29.4749)\n",
      "  3. Feature 14472: 2.61% (value: 26.0115)\n",
      "  4. Feature 3481: 2.49% (value: 25.3980)\n",
      "  5. Feature 8550: 2.20% (value: 23.8791)\n",
      "  6. Feature 579: 2.02% (value: 22.8972)\n",
      "  7. Feature 12370: 2.00% (value: 22.7649)\n",
      "  8. Feature 9401: 1.99% (value: 22.7395)\n",
      "  9. Feature 8398: 1.99% (value: 22.7105)\n",
      "  10. Feature 5475: 1.79% (value: 21.5547)\n",
      "Number of non-zero features: 233\n",
      "\n",
      "Behavior: survival-instinct\n",
      "Total norm: 146.4192\n",
      "Top 10 contributing features:\n",
      "  1. Feature 8550: 8.49% (value: 42.6656)\n",
      "  2. Feature 4107: 5.56% (value: 34.5352)\n",
      "  3. Feature 10781: 5.41% (value: 34.0646)\n",
      "  4. Feature 1582: 3.74% (value: 28.3157)\n",
      "  5. Feature 7822: 2.52% (value: 23.2607)\n",
      "  6. Feature 11139: 2.41% (value: 22.7225)\n",
      "  7. Feature 3253: 1.80% (value: 19.6624)\n",
      "  8. Feature 11113: 1.76% (value: 19.4048)\n",
      "  9. Feature 12369: 1.47% (value: 17.7247)\n",
      "  10. Feature 12265: 1.32% (value: 16.7929)\n",
      "Number of non-zero features: 341\n",
      "\n",
      "Behavior: sycophancy\n",
      "Total norm: 138.8502\n",
      "Top 10 contributing features:\n",
      "  1. Feature 7655: 6.26% (value: 34.7330)\n",
      "  2. Feature 15056: 5.35% (value: 32.1114)\n",
      "  3. Feature 1082: 5.29% (value: 31.9303)\n",
      "  4. Feature 4107: 2.91% (value: 23.7054)\n",
      "  5. Feature 11947: 2.89% (value: 23.6183)\n",
      "  6. Feature 1213: 2.03% (value: 19.7918)\n",
      "  7. Feature 8517: 1.67% (value: 17.9225)\n",
      "  8. Feature 3734: 1.62% (value: 17.6929)\n",
      "  9. Feature 14769: 1.57% (value: 17.4199)\n",
      "  10. Feature 1830: 1.57% (value: 17.3827)\n",
      "Number of non-zero features: 343\n",
      "\n",
      "Behavior: refusal\n",
      "Total norm: 150.2682\n",
      "Top 10 contributing features:\n",
      "  1. Feature 15297: 3.58% (value: 28.4289)\n",
      "  2. Feature 1538: 3.55% (value: 28.3076)\n",
      "  3. Feature 13748: 3.14% (value: 26.6420)\n",
      "  4. Feature 1462: 3.07% (value: 26.3455)\n",
      "  5. Feature 6648: 3.01% (value: 26.0690)\n",
      "  6. Feature 9286: 1.96% (value: 21.0437)\n",
      "  7. Feature 14929: 1.55% (value: 18.7217)\n",
      "  8. Feature 1618: 1.55% (value: 18.7019)\n",
      "  9. Feature 9868: 1.48% (value: 18.2508)\n",
      "  10. Feature 12085: 1.36% (value: 17.5409)\n",
      "Number of non-zero features: 364\n",
      "\n",
      "Behavior feature analysis saved to /root/CAA/sae_vector/behavior_feature_analysis.pt\n"
     ]
    }
   ],
   "source": [
    "# Assuming sae, caa_vectors, device, and sae_vector_dir are already defined\n",
    "\n",
    "def analyze_behavior_vector(behavior, caa_vector):\n",
    "    caa_vector = caa_vector.to(device)\n",
    "    \n",
    "    # Process the CAA vector through the encoder to get the encoded (SAE basis) vector\n",
    "    encoded_vector = sae.encode(caa_vector * 4.2813 + sae.b_dec)\n",
    "    \n",
    "    # Calculate the squared values of the encoded vector\n",
    "    squared_values = encoded_vector ** 2\n",
    "    \n",
    "    # Calculate the total sum of squared values\n",
    "    total_squared_sum = torch.sum(squared_values).item()\n",
    "    \n",
    "    # Calculate the contribution of each feature\n",
    "    feature_contributions = []\n",
    "    for i, feature_value in enumerate(encoded_vector):\n",
    "        feature_squared = feature_value.item() ** 2\n",
    "        percentage = (feature_squared / total_squared_sum) * 100 if total_squared_sum != 0 else 0\n",
    "        feature_contributions.append((i, feature_value.item(), percentage))\n",
    "    \n",
    "    # Sort features by their contribution (descending order)\n",
    "    sorted_features = sorted(feature_contributions, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    return sorted_features, torch.sqrt(torch.tensor(total_squared_sum)).item()\n",
    "\n",
    "# Analyze each behavior\n",
    "behavior_analyses = {}\n",
    "\n",
    "for behavior, caa_vector in caa_vectors.items():\n",
    "    sorted_features, total_norm = analyze_behavior_vector(behavior, caa_vector)\n",
    "    behavior_analyses[behavior] = {\n",
    "        \"sorted_features\": sorted_features,\n",
    "        \"total_norm\": total_norm\n",
    "    }\n",
    "\n",
    "# Print results\n",
    "for behavior, analysis in behavior_analyses.items():\n",
    "    print(f\"\\nBehavior: {behavior}\")\n",
    "    print(f\"Total norm: {analysis['total_norm']:.4f}\")\n",
    "    print(\"Top 10 contributing features:\")\n",
    "    for i, (feature_index, feature_value, percentage) in enumerate(analysis['sorted_features'][:10], 1):\n",
    "        print(f\"  {i}. Feature {feature_index}: {percentage:.2f}% (value: {feature_value:.4f})\")\n",
    "    \n",
    "    # Count non-zero features\n",
    "    non_zero_count = sum(1 for _, value, _ in analysis['sorted_features'] if abs(value) > 1e-6)\n",
    "    print(f\"Number of non-zero features: {non_zero_count}\")\n",
    "\n",
    "# Optionally, save the analysis results\n",
    "save_path = os.path.join(sae_vector_dir, \"behavior_feature_analysis.pt\")\n",
    "torch.save(behavior_analyses, save_path)\n",
    "print(f\"\\nBehavior feature analysis saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of original refusal vector: 44.3626\n",
      "Feature 7655: structured data, such as XML or JSON formats\n",
      "Component vector norm: 34.7330\n",
      "Feature 15056: references to medical and statistical terms related to health conditions and treatments\n",
      "Component vector norm: 32.1114\n",
      "Feature 1082: references to legal terms and concepts related to judgment and advocacy\n",
      "Component vector norm: 31.9303\n",
      "Feature 4107: mathematical or scientific concepts related to assumptions and models in research\n",
      "Component vector norm: 23.7054\n",
      "Feature 11947: elements related to changes in weight or prevalence of health issues over time\n",
      "Component vector norm: 23.6183\n",
      "Feature 1213: technical details related to networks, affiliations, and geographical or situational references\n",
      "Component vector norm: 19.7918\n",
      "Feature 8517: HTML and code structure elements related to validation functionality\n",
      "Component vector norm: 17.9225\n",
      "Feature 3734: instructions and specifications related to product orders and processing\n",
      "Component vector norm: 17.6929\n",
      "Feature 14769: elements and themes related to character actions and dynamics in a narrative\n",
      "Component vector norm: 17.4199\n",
      "Feature 1830: statistical relationships and results in medical and scientific research\n",
      "Component vector norm: 17.3827\n",
      "Feature 11162:  mathematical expressions and contact terms\n",
      "Component vector norm: 15.4343\n",
      "Feature 6677: locations and references to health-related conditions or items\n",
      "Component vector norm: 15.2742\n",
      "Feature 10206:  phrases discussing the functionality and performance of software or hardware features\n",
      "Component vector norm: 15.0305\n",
      "Feature 15611:  questions and statements related to comparisons and choices\n",
      "Component vector norm: 14.7380\n",
      "Feature 3504: technical terms and definitions related to programming and software context\n",
      "Component vector norm: 14.5910\n",
      "Feature 3823: phrases related to disagreement or response in a dialogue\n",
      "Component vector norm: 12.9458\n",
      "Feature 15887: numerical and legal references, particularly those related to cases or statutes\n",
      "Component vector norm: 12.5645\n",
      "Feature 3497: structure and syntax related to programming or markup language elements\n",
      "Component vector norm: 12.4500\n",
      "Feature 14080: quantitative assessments and ratings of films or artistic works\n",
      "Component vector norm: 11.9605\n",
      "Feature 45: medical or clinical terms related to research and diagnoses\n",
      "Component vector norm: 11.6447\n",
      "Feature 9164:  mathematical terms related to gauge theories and transformations\n",
      "Component vector norm: 11.5952\n",
      "Feature 11575: mathematical or quantitative concepts, particularly those involving calculations or definitions\n",
      "Component vector norm: 11.4209\n",
      "Feature 2791: variables and attributes related to categories and classifications in data\n",
      "Component vector norm: 11.1307\n",
      "Feature 14314: references to strong or tough characters or themes\n",
      "Component vector norm: 11.1020\n",
      "Feature 3371: contrasting elements and comparisons within discussions\n",
      "Component vector norm: 11.0122\n",
      "Feature 14133: technical terms and phrases related to medical or scientific contexts\n",
      "Component vector norm: 10.8727\n",
      "Feature 8515: concepts related to collaboration and research networks\n",
      "Component vector norm: 10.8158\n",
      "Feature 2937: elements related to programming structures, such as classes and methods\n",
      "Component vector norm: 10.7129\n",
      "Feature 4462: references to legal terminology and procedures\n",
      "Component vector norm: 10.4390\n",
      "Feature 7533: references to medical or scientific terminology\n",
      "Component vector norm: 10.3239\n",
      "Feature 7430: references to rural and remote settings\n",
      "Component vector norm: 10.2673\n",
      "Feature 15158: references to scientific research and education\n",
      "Component vector norm: 10.2032\n",
      "Feature 10652: specific elements related to legal and regulatory processes, particularly concerning court proceedings and fines\n",
      "Component vector norm: 10.0834\n",
      "Feature 10414: statistical comparisons and regulatory language related to income and taxation\n",
      "Component vector norm: 10.0054\n",
      "Feature 10295: mentions of specific individuals, locations, and contextually relevant details\n",
      "Component vector norm: 9.8820\n",
      "Feature 11701: references to specific events or organizations\n",
      "Component vector norm: 9.5446\n",
      "Feature 5212: terms related to machine learning methodologies and evaluation metrics\n",
      "Component vector norm: 9.4265\n",
      "Feature 1677: technical terminology and structures related to engineering and technology\n",
      "Component vector norm: 9.3731\n",
      "Feature 7368: instances of the word \"description\" and related attributes in a structured data format\n",
      "Component vector norm: 9.3394\n",
      "Feature 12318: syntactic structures related to data types and their definitions\n",
      "Component vector norm: 9.1929\n",
      "Feature 9116: textual elements that indicate state changes or significant events\n",
      "Component vector norm: 9.1843\n",
      "Feature 13057: references to specific biological processes and entities related to immune response and metabolism\n",
      "Component vector norm: 9.1780\n",
      "Feature 9871: key terminologies and structural elements related to viruses and their properties\n",
      "Component vector norm: 9.1367\n",
      "Feature 5558: scientific terms and concepts related to research and testing processes\n",
      "Component vector norm: 9.1314\n",
      "Feature 6473: references to specific organizations or entities involved in studies and trials\n",
      "Component vector norm: 8.7436\n",
      "Feature 5480: technical or scientific terminology related to standards and definitions\n",
      "Component vector norm: 8.6585\n",
      "Feature 14452: references to studies, reports, and evaluations in various contexts\n",
      "Component vector norm: 8.6036\n",
      "Feature 10261: references to specific individuals and their roles or contributions in various contexts\n",
      "Component vector norm: 8.4848\n",
      "Feature 4378: phrases related to societal norms and integrity in professional contexts\n",
      "Component vector norm: 8.4581\n",
      "Feature 6699: references to historical figures and events\n",
      "Component vector norm: 8.3562\n",
      "Behavior: sycophancy\n",
      "Top features by impact (index, impact, explanation, component norm):\n",
      "Index: 7655, Impact: 34.7330, Component Norm: 34.7330\n",
      "Explanation: structured data, such as XML or JSON formats\n",
      "\n",
      "Index: 15056, Impact: 32.1114, Component Norm: 32.1114\n",
      "Explanation: references to medical and statistical terms related to health conditions and treatments\n",
      "\n",
      "Index: 1082, Impact: 31.9303, Component Norm: 31.9303\n",
      "Explanation: references to legal terms and concepts related to judgment and advocacy\n",
      "\n",
      "Index: 4107, Impact: 23.7054, Component Norm: 23.7054\n",
      "Explanation: mathematical or scientific concepts related to assumptions and models in research\n",
      "\n",
      "Index: 11947, Impact: 23.6183, Component Norm: 23.6183\n",
      "Explanation: elements related to changes in weight or prevalence of health issues over time\n",
      "\n",
      "Index: 1213, Impact: 19.7918, Component Norm: 19.7918\n",
      "Explanation: technical details related to networks, affiliations, and geographical or situational references\n",
      "\n",
      "Index: 8517, Impact: 17.9225, Component Norm: 17.9225\n",
      "Explanation: HTML and code structure elements related to validation functionality\n",
      "\n",
      "Index: 3734, Impact: 17.6929, Component Norm: 17.6929\n",
      "Explanation: instructions and specifications related to product orders and processing\n",
      "\n",
      "Index: 14769, Impact: 17.4199, Component Norm: 17.4199\n",
      "Explanation: elements and themes related to character actions and dynamics in a narrative\n",
      "\n",
      "Index: 1830, Impact: 17.3827, Component Norm: 17.3827\n",
      "Explanation: statistical relationships and results in medical and scientific research\n",
      "\n",
      "Index: 11162, Impact: 15.4343, Component Norm: 15.4343\n",
      "Explanation:  mathematical expressions and contact terms\n",
      "\n",
      "Index: 6677, Impact: 15.2742, Component Norm: 15.2742\n",
      "Explanation: locations and references to health-related conditions or items\n",
      "\n",
      "Index: 10206, Impact: 15.0305, Component Norm: 15.0305\n",
      "Explanation:  phrases discussing the functionality and performance of software or hardware features\n",
      "\n",
      "Index: 15611, Impact: 14.7380, Component Norm: 14.7380\n",
      "Explanation:  questions and statements related to comparisons and choices\n",
      "\n",
      "Index: 3504, Impact: 14.5910, Component Norm: 14.5910\n",
      "Explanation: technical terms and definitions related to programming and software context\n",
      "\n",
      "Index: 3823, Impact: 12.9458, Component Norm: 12.9458\n",
      "Explanation: phrases related to disagreement or response in a dialogue\n",
      "\n",
      "Index: 15887, Impact: 12.5645, Component Norm: 12.5645\n",
      "Explanation: numerical and legal references, particularly those related to cases or statutes\n",
      "\n",
      "Index: 3497, Impact: 12.4500, Component Norm: 12.4500\n",
      "Explanation: structure and syntax related to programming or markup language elements\n",
      "\n",
      "Index: 14080, Impact: 11.9605, Component Norm: 11.9605\n",
      "Explanation: quantitative assessments and ratings of films or artistic works\n",
      "\n",
      "Index: 45, Impact: 11.6447, Component Norm: 11.6447\n",
      "Explanation: medical or clinical terms related to research and diagnoses\n",
      "\n",
      "Index: 9164, Impact: 11.5952, Component Norm: 11.5952\n",
      "Explanation:  mathematical terms related to gauge theories and transformations\n",
      "\n",
      "Index: 11575, Impact: 11.4209, Component Norm: 11.4209\n",
      "Explanation: mathematical or quantitative concepts, particularly those involving calculations or definitions\n",
      "\n",
      "Index: 2791, Impact: 11.1307, Component Norm: 11.1307\n",
      "Explanation: variables and attributes related to categories and classifications in data\n",
      "\n",
      "Index: 14314, Impact: 11.1020, Component Norm: 11.1020\n",
      "Explanation: references to strong or tough characters or themes\n",
      "\n",
      "Index: 3371, Impact: 11.0122, Component Norm: 11.0122\n",
      "Explanation: contrasting elements and comparisons within discussions\n",
      "\n",
      "Index: 14133, Impact: 10.8727, Component Norm: 10.8727\n",
      "Explanation: technical terms and phrases related to medical or scientific contexts\n",
      "\n",
      "Index: 8515, Impact: 10.8158, Component Norm: 10.8158\n",
      "Explanation: concepts related to collaboration and research networks\n",
      "\n",
      "Index: 2937, Impact: 10.7129, Component Norm: 10.7129\n",
      "Explanation: elements related to programming structures, such as classes and methods\n",
      "\n",
      "Index: 4462, Impact: 10.4390, Component Norm: 10.4390\n",
      "Explanation: references to legal terminology and procedures\n",
      "\n",
      "Index: 7533, Impact: 10.3239, Component Norm: 10.3239\n",
      "Explanation: references to medical or scientific terminology\n",
      "\n",
      "Index: 7430, Impact: 10.2673, Component Norm: 10.2673\n",
      "Explanation: references to rural and remote settings\n",
      "\n",
      "Index: 15158, Impact: 10.2032, Component Norm: 10.2032\n",
      "Explanation: references to scientific research and education\n",
      "\n",
      "Index: 10652, Impact: 10.0834, Component Norm: 10.0834\n",
      "Explanation: specific elements related to legal and regulatory processes, particularly concerning court proceedings and fines\n",
      "\n",
      "Index: 10414, Impact: 10.0054, Component Norm: 10.0054\n",
      "Explanation: statistical comparisons and regulatory language related to income and taxation\n",
      "\n",
      "Index: 10295, Impact: 9.8820, Component Norm: 9.8820\n",
      "Explanation: mentions of specific individuals, locations, and contextually relevant details\n",
      "\n",
      "Index: 11701, Impact: 9.5446, Component Norm: 9.5446\n",
      "Explanation: references to specific events or organizations\n",
      "\n",
      "Index: 5212, Impact: 9.4265, Component Norm: 9.4265\n",
      "Explanation: terms related to machine learning methodologies and evaluation metrics\n",
      "\n",
      "Index: 1677, Impact: 9.3731, Component Norm: 9.3731\n",
      "Explanation: technical terminology and structures related to engineering and technology\n",
      "\n",
      "Index: 7368, Impact: 9.3394, Component Norm: 9.3394\n",
      "Explanation: instances of the word \"description\" and related attributes in a structured data format\n",
      "\n",
      "Index: 12318, Impact: 9.1929, Component Norm: 9.1929\n",
      "Explanation: syntactic structures related to data types and their definitions\n",
      "\n",
      "Index: 9116, Impact: 9.1843, Component Norm: 9.1843\n",
      "Explanation: textual elements that indicate state changes or significant events\n",
      "\n",
      "Index: 13057, Impact: 9.1780, Component Norm: 9.1780\n",
      "Explanation: references to specific biological processes and entities related to immune response and metabolism\n",
      "\n",
      "Index: 9871, Impact: 9.1367, Component Norm: 9.1367\n",
      "Explanation: key terminologies and structural elements related to viruses and their properties\n",
      "\n",
      "Index: 5558, Impact: 9.1314, Component Norm: 9.1314\n",
      "Explanation: scientific terms and concepts related to research and testing processes\n",
      "\n",
      "Index: 6473, Impact: 8.7436, Component Norm: 8.7436\n",
      "Explanation: references to specific organizations or entities involved in studies and trials\n",
      "\n",
      "Index: 5480, Impact: 8.6585, Component Norm: 8.6585\n",
      "Explanation: technical or scientific terminology related to standards and definitions\n",
      "\n",
      "Index: 14452, Impact: 8.6036, Component Norm: 8.6036\n",
      "Explanation: references to studies, reports, and evaluations in various contexts\n",
      "\n",
      "Index: 10261, Impact: 8.4848, Component Norm: 8.4848\n",
      "Explanation: references to specific individuals and their roles or contributions in various contexts\n",
      "\n",
      "Index: 4378, Impact: 8.4581, Component Norm: 8.4581\n",
      "Explanation: phrases related to societal norms and integrity in professional contexts\n",
      "\n",
      "Index: 6699, Impact: 8.3562, Component Norm: 8.3562\n",
      "Explanation: references to historical figures and events\n",
      "\n",
      "Component vector for feature 7655 saved to sae_vector_features/sycophancy/feature_7655_component_vector.pt\n",
      "Dimension of component vector for feature 7655: torch.Size([2304])\n",
      "Component vector for feature 15056 saved to sae_vector_features/sycophancy/feature_15056_component_vector.pt\n",
      "Dimension of component vector for feature 15056: torch.Size([2304])\n",
      "Component vector for feature 1082 saved to sae_vector_features/sycophancy/feature_1082_component_vector.pt\n",
      "Dimension of component vector for feature 1082: torch.Size([2304])\n",
      "Component vector for feature 4107 saved to sae_vector_features/sycophancy/feature_4107_component_vector.pt\n",
      "Dimension of component vector for feature 4107: torch.Size([2304])\n",
      "Component vector for feature 11947 saved to sae_vector_features/sycophancy/feature_11947_component_vector.pt\n",
      "Dimension of component vector for feature 11947: torch.Size([2304])\n",
      "Component vector for feature 1213 saved to sae_vector_features/sycophancy/feature_1213_component_vector.pt\n",
      "Dimension of component vector for feature 1213: torch.Size([2304])\n",
      "Component vector for feature 8517 saved to sae_vector_features/sycophancy/feature_8517_component_vector.pt\n",
      "Dimension of component vector for feature 8517: torch.Size([2304])\n",
      "Component vector for feature 3734 saved to sae_vector_features/sycophancy/feature_3734_component_vector.pt\n",
      "Dimension of component vector for feature 3734: torch.Size([2304])\n",
      "Component vector for feature 14769 saved to sae_vector_features/sycophancy/feature_14769_component_vector.pt\n",
      "Dimension of component vector for feature 14769: torch.Size([2304])\n",
      "Component vector for feature 1830 saved to sae_vector_features/sycophancy/feature_1830_component_vector.pt\n",
      "Dimension of component vector for feature 1830: torch.Size([2304])\n",
      "Component vector for feature 11162 saved to sae_vector_features/sycophancy/feature_11162_component_vector.pt\n",
      "Dimension of component vector for feature 11162: torch.Size([2304])\n",
      "Component vector for feature 6677 saved to sae_vector_features/sycophancy/feature_6677_component_vector.pt\n",
      "Dimension of component vector for feature 6677: torch.Size([2304])\n",
      "Component vector for feature 10206 saved to sae_vector_features/sycophancy/feature_10206_component_vector.pt\n",
      "Dimension of component vector for feature 10206: torch.Size([2304])\n",
      "Component vector for feature 15611 saved to sae_vector_features/sycophancy/feature_15611_component_vector.pt\n",
      "Dimension of component vector for feature 15611: torch.Size([2304])\n",
      "Component vector for feature 3504 saved to sae_vector_features/sycophancy/feature_3504_component_vector.pt\n",
      "Dimension of component vector for feature 3504: torch.Size([2304])\n",
      "Component vector for feature 3823 saved to sae_vector_features/sycophancy/feature_3823_component_vector.pt\n",
      "Dimension of component vector for feature 3823: torch.Size([2304])\n",
      "Component vector for feature 15887 saved to sae_vector_features/sycophancy/feature_15887_component_vector.pt\n",
      "Dimension of component vector for feature 15887: torch.Size([2304])\n",
      "Component vector for feature 3497 saved to sae_vector_features/sycophancy/feature_3497_component_vector.pt\n",
      "Dimension of component vector for feature 3497: torch.Size([2304])\n",
      "Component vector for feature 14080 saved to sae_vector_features/sycophancy/feature_14080_component_vector.pt\n",
      "Dimension of component vector for feature 14080: torch.Size([2304])\n",
      "Component vector for feature 45 saved to sae_vector_features/sycophancy/feature_45_component_vector.pt\n",
      "Dimension of component vector for feature 45: torch.Size([2304])\n",
      "Component vector for feature 9164 saved to sae_vector_features/sycophancy/feature_9164_component_vector.pt\n",
      "Dimension of component vector for feature 9164: torch.Size([2304])\n",
      "Component vector for feature 11575 saved to sae_vector_features/sycophancy/feature_11575_component_vector.pt\n",
      "Dimension of component vector for feature 11575: torch.Size([2304])\n",
      "Component vector for feature 2791 saved to sae_vector_features/sycophancy/feature_2791_component_vector.pt\n",
      "Dimension of component vector for feature 2791: torch.Size([2304])\n",
      "Component vector for feature 14314 saved to sae_vector_features/sycophancy/feature_14314_component_vector.pt\n",
      "Dimension of component vector for feature 14314: torch.Size([2304])\n",
      "Component vector for feature 3371 saved to sae_vector_features/sycophancy/feature_3371_component_vector.pt\n",
      "Dimension of component vector for feature 3371: torch.Size([2304])\n",
      "Component vector for feature 14133 saved to sae_vector_features/sycophancy/feature_14133_component_vector.pt\n",
      "Dimension of component vector for feature 14133: torch.Size([2304])\n",
      "Component vector for feature 8515 saved to sae_vector_features/sycophancy/feature_8515_component_vector.pt\n",
      "Dimension of component vector for feature 8515: torch.Size([2304])\n",
      "Component vector for feature 2937 saved to sae_vector_features/sycophancy/feature_2937_component_vector.pt\n",
      "Dimension of component vector for feature 2937: torch.Size([2304])\n",
      "Component vector for feature 4462 saved to sae_vector_features/sycophancy/feature_4462_component_vector.pt\n",
      "Dimension of component vector for feature 4462: torch.Size([2304])\n",
      "Component vector for feature 7533 saved to sae_vector_features/sycophancy/feature_7533_component_vector.pt\n",
      "Dimension of component vector for feature 7533: torch.Size([2304])\n",
      "Component vector for feature 7430 saved to sae_vector_features/sycophancy/feature_7430_component_vector.pt\n",
      "Dimension of component vector for feature 7430: torch.Size([2304])\n",
      "Component vector for feature 15158 saved to sae_vector_features/sycophancy/feature_15158_component_vector.pt\n",
      "Dimension of component vector for feature 15158: torch.Size([2304])\n",
      "Component vector for feature 10652 saved to sae_vector_features/sycophancy/feature_10652_component_vector.pt\n",
      "Dimension of component vector for feature 10652: torch.Size([2304])\n",
      "Component vector for feature 10414 saved to sae_vector_features/sycophancy/feature_10414_component_vector.pt\n",
      "Dimension of component vector for feature 10414: torch.Size([2304])\n",
      "Component vector for feature 10295 saved to sae_vector_features/sycophancy/feature_10295_component_vector.pt\n",
      "Dimension of component vector for feature 10295: torch.Size([2304])\n",
      "Component vector for feature 11701 saved to sae_vector_features/sycophancy/feature_11701_component_vector.pt\n",
      "Dimension of component vector for feature 11701: torch.Size([2304])\n",
      "Component vector for feature 5212 saved to sae_vector_features/sycophancy/feature_5212_component_vector.pt\n",
      "Dimension of component vector for feature 5212: torch.Size([2304])\n",
      "Component vector for feature 1677 saved to sae_vector_features/sycophancy/feature_1677_component_vector.pt\n",
      "Dimension of component vector for feature 1677: torch.Size([2304])\n",
      "Component vector for feature 7368 saved to sae_vector_features/sycophancy/feature_7368_component_vector.pt\n",
      "Dimension of component vector for feature 7368: torch.Size([2304])\n",
      "Component vector for feature 12318 saved to sae_vector_features/sycophancy/feature_12318_component_vector.pt\n",
      "Dimension of component vector for feature 12318: torch.Size([2304])\n",
      "Component vector for feature 9116 saved to sae_vector_features/sycophancy/feature_9116_component_vector.pt\n",
      "Dimension of component vector for feature 9116: torch.Size([2304])\n",
      "Component vector for feature 13057 saved to sae_vector_features/sycophancy/feature_13057_component_vector.pt\n",
      "Dimension of component vector for feature 13057: torch.Size([2304])\n",
      "Component vector for feature 9871 saved to sae_vector_features/sycophancy/feature_9871_component_vector.pt\n",
      "Dimension of component vector for feature 9871: torch.Size([2304])\n",
      "Component vector for feature 5558 saved to sae_vector_features/sycophancy/feature_5558_component_vector.pt\n",
      "Dimension of component vector for feature 5558: torch.Size([2304])\n",
      "Component vector for feature 6473 saved to sae_vector_features/sycophancy/feature_6473_component_vector.pt\n",
      "Dimension of component vector for feature 6473: torch.Size([2304])\n",
      "Component vector for feature 5480 saved to sae_vector_features/sycophancy/feature_5480_component_vector.pt\n",
      "Dimension of component vector for feature 5480: torch.Size([2304])\n",
      "Component vector for feature 14452 saved to sae_vector_features/sycophancy/feature_14452_component_vector.pt\n",
      "Dimension of component vector for feature 14452: torch.Size([2304])\n",
      "Component vector for feature 10261 saved to sae_vector_features/sycophancy/feature_10261_component_vector.pt\n",
      "Dimension of component vector for feature 10261: torch.Size([2304])\n",
      "Component vector for feature 4378 saved to sae_vector_features/sycophancy/feature_4378_component_vector.pt\n",
      "Dimension of component vector for feature 4378: torch.Size([2304])\n",
      "Component vector for feature 6699 saved to sae_vector_features/sycophancy/feature_6699_component_vector.pt\n",
      "Dimension of component vector for feature 6699: torch.Size([2304])\n",
      "Top k feature explanations and component vectors by impact saved to sae_vector_features/sycophancy/top_20_features_explanations_refusal.pt\n",
      "Component vector for feature 7655 saved to sae_vector_features/sycophancy/feature_7655_component_vector.pt\n",
      "Component vector for feature 15056 saved to sae_vector_features/sycophancy/feature_15056_component_vector.pt\n",
      "Component vector for feature 1082 saved to sae_vector_features/sycophancy/feature_1082_component_vector.pt\n",
      "Component vector for feature 4107 saved to sae_vector_features/sycophancy/feature_4107_component_vector.pt\n",
      "Component vector for feature 11947 saved to sae_vector_features/sycophancy/feature_11947_component_vector.pt\n",
      "Component vector for feature 1213 saved to sae_vector_features/sycophancy/feature_1213_component_vector.pt\n",
      "Component vector for feature 8517 saved to sae_vector_features/sycophancy/feature_8517_component_vector.pt\n",
      "Component vector for feature 3734 saved to sae_vector_features/sycophancy/feature_3734_component_vector.pt\n",
      "Component vector for feature 14769 saved to sae_vector_features/sycophancy/feature_14769_component_vector.pt\n",
      "Component vector for feature 1830 saved to sae_vector_features/sycophancy/feature_1830_component_vector.pt\n",
      "Component vector for feature 11162 saved to sae_vector_features/sycophancy/feature_11162_component_vector.pt\n",
      "Component vector for feature 6677 saved to sae_vector_features/sycophancy/feature_6677_component_vector.pt\n",
      "Component vector for feature 10206 saved to sae_vector_features/sycophancy/feature_10206_component_vector.pt\n",
      "Component vector for feature 15611 saved to sae_vector_features/sycophancy/feature_15611_component_vector.pt\n",
      "Component vector for feature 3504 saved to sae_vector_features/sycophancy/feature_3504_component_vector.pt\n",
      "Component vector for feature 3823 saved to sae_vector_features/sycophancy/feature_3823_component_vector.pt\n",
      "Component vector for feature 15887 saved to sae_vector_features/sycophancy/feature_15887_component_vector.pt\n",
      "Component vector for feature 3497 saved to sae_vector_features/sycophancy/feature_3497_component_vector.pt\n",
      "Component vector for feature 14080 saved to sae_vector_features/sycophancy/feature_14080_component_vector.pt\n",
      "Component vector for feature 45 saved to sae_vector_features/sycophancy/feature_45_component_vector.pt\n",
      "Component vector for feature 9164 saved to sae_vector_features/sycophancy/feature_9164_component_vector.pt\n",
      "Component vector for feature 11575 saved to sae_vector_features/sycophancy/feature_11575_component_vector.pt\n",
      "Component vector for feature 2791 saved to sae_vector_features/sycophancy/feature_2791_component_vector.pt\n",
      "Component vector for feature 14314 saved to sae_vector_features/sycophancy/feature_14314_component_vector.pt\n",
      "Component vector for feature 3371 saved to sae_vector_features/sycophancy/feature_3371_component_vector.pt\n",
      "Component vector for feature 14133 saved to sae_vector_features/sycophancy/feature_14133_component_vector.pt\n",
      "Component vector for feature 8515 saved to sae_vector_features/sycophancy/feature_8515_component_vector.pt\n",
      "Component vector for feature 2937 saved to sae_vector_features/sycophancy/feature_2937_component_vector.pt\n",
      "Component vector for feature 4462 saved to sae_vector_features/sycophancy/feature_4462_component_vector.pt\n",
      "Component vector for feature 7533 saved to sae_vector_features/sycophancy/feature_7533_component_vector.pt\n",
      "Component vector for feature 7430 saved to sae_vector_features/sycophancy/feature_7430_component_vector.pt\n",
      "Component vector for feature 15158 saved to sae_vector_features/sycophancy/feature_15158_component_vector.pt\n",
      "Component vector for feature 10652 saved to sae_vector_features/sycophancy/feature_10652_component_vector.pt\n",
      "Component vector for feature 10414 saved to sae_vector_features/sycophancy/feature_10414_component_vector.pt\n",
      "Component vector for feature 10295 saved to sae_vector_features/sycophancy/feature_10295_component_vector.pt\n",
      "Component vector for feature 11701 saved to sae_vector_features/sycophancy/feature_11701_component_vector.pt\n",
      "Component vector for feature 5212 saved to sae_vector_features/sycophancy/feature_5212_component_vector.pt\n",
      "Component vector for feature 1677 saved to sae_vector_features/sycophancy/feature_1677_component_vector.pt\n",
      "Component vector for feature 7368 saved to sae_vector_features/sycophancy/feature_7368_component_vector.pt\n",
      "Component vector for feature 12318 saved to sae_vector_features/sycophancy/feature_12318_component_vector.pt\n",
      "Component vector for feature 9116 saved to sae_vector_features/sycophancy/feature_9116_component_vector.pt\n",
      "Component vector for feature 13057 saved to sae_vector_features/sycophancy/feature_13057_component_vector.pt\n",
      "Component vector for feature 9871 saved to sae_vector_features/sycophancy/feature_9871_component_vector.pt\n",
      "Component vector for feature 5558 saved to sae_vector_features/sycophancy/feature_5558_component_vector.pt\n",
      "Component vector for feature 6473 saved to sae_vector_features/sycophancy/feature_6473_component_vector.pt\n",
      "Component vector for feature 5480 saved to sae_vector_features/sycophancy/feature_5480_component_vector.pt\n",
      "Component vector for feature 14452 saved to sae_vector_features/sycophancy/feature_14452_component_vector.pt\n",
      "Component vector for feature 10261 saved to sae_vector_features/sycophancy/feature_10261_component_vector.pt\n",
      "Component vector for feature 4378 saved to sae_vector_features/sycophancy/feature_4378_component_vector.pt\n",
      "Component vector for feature 6699 saved to sae_vector_features/sycophancy/feature_6699_component_vector.pt\n",
      "Top k feature explanations and component vectors by impact saved to sae_vector_features/sycophancy/top_k_features_explanations_refusal.pt\n"
     ]
    }
   ],
   "source": [
    "# Neuronpedia API Information\n",
    "API_KEY = os.getenv(\"NEURONPEDIA_API_KEY\")\n",
    "API_URL = \"https://www.neuronpedia.org/api/feature/{modelId}/{layer}/{index}\"\n",
    "\n",
    "def fetch_feature_explanation(model_id, layer, index, max_retries=3):\n",
    "    if not API_KEY:\n",
    "        return f\"Feature {index}: No API key provided. Unable to fetch explanation.\"\n",
    "\n",
    "    url = API_URL.format(modelId=model_id, layer=layer, index=index)\n",
    "    headers = {\n",
    "        \"X-Api-Key\": API_KEY\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            explanations = data.get(\"explanations\", [])\n",
    "            if explanations:\n",
    "                return explanations[0].get(\"description\", \"No description available\")\n",
    "            else:\n",
    "                return \"No explanation available from API\"\n",
    "        except requests.exceptions.RequestException as err:\n",
    "            print(f\"Error occurred (attempt {attempt + 1}/{max_retries}): {err}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2)\n",
    "    \n",
    "    return f\"Feature {index}: Failed to retrieve explanation after {max_retries} attempts\"\n",
    "\n",
    "# Process and sort features by impact for behavior\n",
    "model_id = \"gemma-2-2b\"\n",
    "layer_id = \"14-gemmascope-res-16k\"\n",
    "behavior = \"sycophancy\"\n",
    "\n",
    "# Assuming caa_vectors and sae are defined elsewhere in your code\n",
    "caa_vector = caa_vectors[behavior].to(device)\n",
    "encoded_vector = sae.encode(caa_vector * 4.2813 + sae.b_dec)\n",
    "\n",
    "non_zero_indices_encoded = torch.nonzero(encoded_vector).squeeze()\n",
    "non_zero_activations = encoded_vector[non_zero_indices_encoded]\n",
    "\n",
    "impacts = []\n",
    "component_vectors = {}\n",
    "for i, index in enumerate(non_zero_indices_encoded):\n",
    "    contribution_vector = sae.W_dec[index, :] * non_zero_activations[i]\n",
    "    impact = torch.norm(contribution_vector).item()\n",
    "    impacts.append((index.item(), impact))\n",
    "    component_vectors[index.item()] = contribution_vector\n",
    "\n",
    "impacts_sorted = sorted(impacts, key=lambda x: x[1], reverse=True)[:50]\n",
    "\n",
    "# Calculate and print the norm of the original refusal vector\n",
    "original_norm = torch.norm(caa_vector).item()\n",
    "print(f\"Norm of original refusal vector: {original_norm:.4f}\")\n",
    "\n",
    "# Fetch explanations for top k features\n",
    "top_features_with_explanations = []\n",
    "for index, impact in impacts_sorted:\n",
    "    explanation = fetch_feature_explanation(model_id, layer_id, index)\n",
    "    component_vector = component_vectors[index]\n",
    "    component_norm = torch.norm(component_vector).item()\n",
    "    top_features_with_explanations.append((index, impact, explanation, component_vector, component_norm))\n",
    "    print(f\"Feature {index}: {explanation}\")\n",
    "    print(f\"Component vector norm: {component_norm:.4f}\")\n",
    "\n",
    "# Print the top features with explanations\n",
    "print(f\"Behavior: {behavior}\")\n",
    "print(f\"Top features by impact (index, impact, explanation, component norm):\")\n",
    "for index, impact, explanation, component_vector, component_norm in top_features_with_explanations:\n",
    "    print(f\"Index: {index}, Impact: {impact:.4f}, Component Norm: {component_norm:.4f}\")\n",
    "    print(f\"Explanation: {explanation}\")\n",
    "    print()\n",
    "\n",
    "sae_vector_dir = f\"sae_vector_features/{behavior}\"\n",
    "os.makedirs(sae_vector_dir, exist_ok=True)\n",
    "\n",
    "for index, impact, explanation, component_vector, component_norm in top_features_with_explanations:\n",
    "    feature_save_path = os.path.join(sae_vector_dir, f\"feature_{index}_component_vector.pt\")\n",
    "    torch.save(component_vector, feature_save_path)\n",
    "    print(f\"Component vector for feature {index} saved to {feature_save_path}\")\n",
    "    print(f\"Dimension of component vector for feature {index}: {component_vector.shape}\")\n",
    "\n",
    "save_path = os.path.join(sae_vector_dir, \"top_20_features_explanations_refusal.pt\")\n",
    "torch.save(top_features_with_explanations, save_path)\n",
    "print(f\"Top k feature explanations and component vectors by impact saved to {save_path}\")\n",
    "\n",
    "# Save the top k features data and component vectors to files\n",
    "sae_vector_dir = f\"sae_vector_features/{behavior}\"\n",
    "os.makedirs(sae_vector_dir, exist_ok=True)\n",
    "\n",
    "for index, impact, explanation, component_vector, component_norm in top_features_with_explanations:\n",
    "    feature_save_path = os.path.join(sae_vector_dir, f\"feature_{index}_component_vector.pt\")\n",
    "    torch.save(component_vector, feature_save_path)\n",
    "    print(f\"Component vector for feature {index} saved to {feature_save_path}\")\n",
    "\n",
    "save_path = os.path.join(sae_vector_dir, \"top_k_features_explanations_refusal.pt\")\n",
    "torch.save(top_features_with_explanations, save_path)\n",
    "print(f\"Top k feature explanations and component vectors by impact saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE model width: Encoder width = 16384, Decoder width = 16384\n",
      "Parameter containing:\n",
      "tensor([-0.1614, -0.1302, -0.0954,  ...,  0.6045, -0.3325, -0.1574],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#VERIFY SAE SELECTED\n",
    "print(f\"SAE model width: Encoder width = {sae.W_enc.shape[1]}, Decoder width = {sae.W_dec.shape[0]}\")\n",
    "print(sae.b_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: feature_10206_component_vector.pt, Original norm: 15.0305, New norm: 44.3626\n",
      "File: feature_10261_component_vector.pt, Original norm: 8.4848, New norm: 44.3626\n",
      "File: feature_10295_component_vector.pt, Original norm: 9.8820, New norm: 44.3626\n",
      "File: feature_10414_component_vector.pt, Original norm: 10.0054, New norm: 44.3626\n",
      "File: feature_10652_component_vector.pt, Original norm: 10.0834, New norm: 44.3626\n",
      "File: feature_1082_component_vector.pt, Original norm: 31.9303, New norm: 44.3626\n",
      "File: feature_11162_component_vector.pt, Original norm: 15.4343, New norm: 44.3626\n",
      "File: feature_11575_component_vector.pt, Original norm: 11.4209, New norm: 44.3626\n",
      "File: feature_11701_component_vector.pt, Original norm: 9.5446, New norm: 44.3626\n",
      "File: feature_11947_component_vector.pt, Original norm: 23.6183, New norm: 44.3626\n",
      "File: feature_1213_component_vector.pt, Original norm: 19.7918, New norm: 44.3626\n",
      "File: feature_12318_component_vector.pt, Original norm: 9.1929, New norm: 44.3626\n",
      "File: feature_13057_component_vector.pt, Original norm: 9.1780, New norm: 44.3626\n",
      "File: feature_14080_component_vector.pt, Original norm: 11.9605, New norm: 44.3626\n",
      "File: feature_14133_component_vector.pt, Original norm: 10.8727, New norm: 44.3626\n",
      "File: feature_14314_component_vector.pt, Original norm: 11.1020, New norm: 44.3626\n",
      "File: feature_14452_component_vector.pt, Original norm: 8.6036, New norm: 44.3626\n",
      "File: feature_14769_component_vector.pt, Original norm: 17.4199, New norm: 44.3626\n",
      "File: feature_15056_component_vector.pt, Original norm: 32.1114, New norm: 44.3626\n",
      "File: feature_15158_component_vector.pt, Original norm: 10.2032, New norm: 44.3626\n",
      "File: feature_15611_component_vector.pt, Original norm: 14.7380, New norm: 44.3626\n",
      "File: feature_15887_component_vector.pt, Original norm: 12.5645, New norm: 44.3626\n",
      "File: feature_1677_component_vector.pt, Original norm: 9.3731, New norm: 44.3626\n",
      "File: feature_1830_component_vector.pt, Original norm: 17.3827, New norm: 44.3626\n",
      "File: feature_2791_component_vector.pt, Original norm: 11.1307, New norm: 44.3626\n",
      "File: feature_2937_component_vector.pt, Original norm: 10.7129, New norm: 44.3626\n",
      "File: feature_3371_component_vector.pt, Original norm: 11.0122, New norm: 44.3626\n",
      "File: feature_3497_component_vector.pt, Original norm: 12.4500, New norm: 44.3626\n",
      "File: feature_3504_component_vector.pt, Original norm: 14.5910, New norm: 44.3626\n",
      "File: feature_3734_component_vector.pt, Original norm: 17.6929, New norm: 44.3626\n",
      "File: feature_3823_component_vector.pt, Original norm: 12.9458, New norm: 44.3626\n",
      "File: feature_4107_component_vector.pt, Original norm: 23.7054, New norm: 44.3626\n",
      "File: feature_4378_component_vector.pt, Original norm: 8.4581, New norm: 44.3626\n",
      "File: feature_4462_component_vector.pt, Original norm: 10.4390, New norm: 44.3626\n",
      "File: feature_45_component_vector.pt, Original norm: 11.6447, New norm: 44.3626\n",
      "File: feature_5212_component_vector.pt, Original norm: 9.4265, New norm: 44.3626\n",
      "File: feature_5480_component_vector.pt, Original norm: 8.6585, New norm: 44.3626\n",
      "File: feature_5558_component_vector.pt, Original norm: 9.1314, New norm: 44.3626\n",
      "File: feature_6473_component_vector.pt, Original norm: 8.7436, New norm: 44.3626\n",
      "File: feature_6677_component_vector.pt, Original norm: 15.2742, New norm: 44.3626\n",
      "File: feature_6699_component_vector.pt, Original norm: 8.3562, New norm: 44.3626\n",
      "File: feature_7368_component_vector.pt, Original norm: 9.3394, New norm: 44.3626\n",
      "File: feature_7430_component_vector.pt, Original norm: 10.2673, New norm: 44.3626\n",
      "File: feature_7533_component_vector.pt, Original norm: 10.3239, New norm: 44.3626\n",
      "File: feature_7655_component_vector.pt, Original norm: 34.7330, New norm: 44.3626\n",
      "File: feature_8515_component_vector.pt, Original norm: 10.8158, New norm: 44.3626\n",
      "File: feature_8517_component_vector.pt, Original norm: 17.9225, New norm: 44.3626\n",
      "File: feature_9116_component_vector.pt, Original norm: 9.1843, New norm: 44.3626\n",
      "File: feature_9164_component_vector.pt, Original norm: 11.5952, New norm: 44.3626\n",
      "File: feature_9871_component_vector.pt, Original norm: 9.1367, New norm: 44.3626\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'layout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m vector \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(input_path)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate the current norm\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m current_norm \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Normalize the vector\u001b[39;00m\n\u001b[1;32m     26\u001b[0m normalized_vector \u001b[38;5;241m=\u001b[39m vector \u001b[38;5;241m*\u001b[39m (target_norm \u001b[38;5;241m/\u001b[39m current_norm)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/functional.py:1597\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   1591\u001b[0m         norm, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, out\u001b[38;5;241m=\u001b[39mout, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;66;03m# NB. All the repeated code and weird python is to please TorchScript.\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;66;03m#     For a more compact implementation see the relevant function in `_refs/__init__.py`\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m \n\u001b[1;32m   1596\u001b[0m \u001b[38;5;66;03m# We don't do this for MPS or sparse tensors\u001b[39;00m\n\u001b[0;32m-> 1597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayout\u001b[49m \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01min\u001b[39;00m \\\n\u001b[1;32m   1598\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mbackend_registration\u001b[38;5;241m.\u001b[39m_privateuse1_backend_name):\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1600\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dim, (\u001b[38;5;28mint\u001b[39m, torch\u001b[38;5;241m.\u001b[39mSymInt)):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'layout'"
     ]
    }
   ],
   "source": [
    "#Normalization of feature vectors\n",
    "\n",
    "# Set the paths\n",
    "input_dir = 'sae_vector_features/sycophancy/'\n",
    "output_dir = 'sae_vector_features/sycophancy/normalized'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Target norm\n",
    "target_norm = 44.3626\n",
    "\n",
    "# Process each file in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.pt'):\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Load the vector\n",
    "        vector = torch.load(input_path)\n",
    "        \n",
    "        # Calculate the current norm\n",
    "        current_norm = torch.norm(vector).item()\n",
    "        \n",
    "        # Normalize the vector\n",
    "        normalized_vector = vector * (target_norm / current_norm)\n",
    "        \n",
    "        # Verify the new norm (optional, for debugging)\n",
    "        new_norm = torch.norm(normalized_vector).item()\n",
    "        print(f\"File: {filename}, Original norm: {current_norm:.4f}, New norm: {new_norm:.4f}\")\n",
    "        \n",
    "        # Save the normalized vector\n",
    "        torch.save(normalized_vector, output_path)\n",
    "\n",
    "print(\"Normalization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
